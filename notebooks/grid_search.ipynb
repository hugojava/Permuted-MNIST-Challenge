{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced8d6df",
   "metadata": {},
   "source": [
    "# **Recherche d’hyperparamètres - Stratégie structurée et contrainte**\n",
    "\n",
    "## **Objectif du notebook**\n",
    "L’objectif de ce notebook est de concevoir une **recherche d’hyperparamètres rigoureuse, efficace et reproductible** pour nos agents du challenge *Permuted MNIST*.  \n",
    "Contrairement à une recherche aléatoire exhaustive ou non contrôlée, l’approche présentée ici repose sur une **méthodologie progressive et modulaire**, adaptée aux **contraintes strictes de la plateforme** et à la **nature du problème** (classification multi-tâches sur données d’images permutées).\n",
    "\n",
    "---\n",
    "\n",
    "## **Contexte et contraintes**\n",
    "Le challenge impose plusieurs contraintes matérielles et temporelles fortes :\n",
    "- **CPU-only**, sans GPU autorisé  \n",
    "- **2 threads maximum** pour le calcul  \n",
    "- **Mémoire ≤ 4 Go**\n",
    "- **Temps d’exécution par task ≤ 60 secondes**, incluant :\n",
    "  - initialisation de l’agent  \n",
    "  - apprentissage  \n",
    "  - prédiction sur le jeu de test\n",
    "\n",
    "Ces limitations interdisent l’utilisation de modèles trop lourds (notamment convolutionnels), ce qui oriente naturellement vers des **architectures MLP** optimisées pour la vitesse et la stabilité en CPU.\n",
    "\n",
    "---\n",
    "\n",
    "## **Philosophie de la recherche**\n",
    "L’objectif n’est pas simplement de “lancer un grid search géant”, mais de **construire un protocole méthodique d’exploration** :\n",
    "1. **Définir un espace de recherche raisonnable**, centré sur les hyperparamètres réellement influents (taille des couches, dropout, batch size, learning rate, label smoothing, etc.).  \n",
    "2. **Évaluer progressivement** les configurations selon une stratégie multi-phases avec **pruning adaptatif**, permettant d’éliminer très tôt les modèles inefficaces.  \n",
    "3. **Mesurer systématiquement** les performances et les temps d’exécution pour chaque configuration, afin de concilier **précision et faisabilité temporelle**.  \n",
    "4. **Conserver les résultats complets** (CSV + JSON) à chaque étape pour analyse et traçabilité.  \n",
    "\n",
    "Cette approche vise à **reproduire le raisonnement scientifique** d’un tuning rigoureux : formuler des hypothèses, les tester sous contrainte, et retenir les modèles présentant le meilleur compromis entre **performance, robustesse et efficacité temporelle**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Structure de la démarche**\n",
    "La recherche se déroule en **trois phases successives**, chacune avec un rôle précis :\n",
    "\n",
    "| Phase | Objectif | # Tasks | Pruning | Description |\n",
    "|:------|:----------|:--------|:---------|:-------------|\n",
    "| **A — Exploration large** | Balayer un grand nombre de combinaisons pour identifier les tendances globales. | 3 | Oui | Permet de repérer rapidement les hyperparamètres prometteurs tout en éliminant les modèles trop lents ou sous-performants. |\n",
    "| **B — Raffinement** | Confirmer les meilleures configurations issues de la phase A. | 6 | Oui | Évaluation plus stable, seuils de pruning plus exigeants. |\n",
    "| **C — Validation finale** | Mesurer la robustesse statistique des top modèles. | 10 | Non | Évaluation complète sur 10 tasks pour obtenir des moyennes et écarts-types représentatifs. |\n",
    "\n",
    "Chaque phase produit un rapport CSV (et un résumé JSON) enregistrant :\n",
    "- la configuration exacte testée ;\n",
    "- la moyenne et l’écart-type des accuracies ;\n",
    "- le temps moyen et total par task ;\n",
    "- les indicateurs de pruning.\n",
    "\n",
    "---\n",
    "\n",
    "## **Principe de modularité**\n",
    "Le code est entièrement **modulaire et réutilisable**.  \n",
    "Il repose sur une série de fonctions génériques qui permettent :\n",
    "- d’instancier dynamiquement un agent via son module (`agent_spec`);\n",
    "- de définir un **espace de recherche** arbitraire (`search_space`);\n",
    "- de contrôler les règles de **pruning** et les tailles d’échantillons par phase ;\n",
    "- d’automatiser toute la séquence `Phase A → Phase B → Phase C` via un unique appel :  \n",
    "  ```python\n",
    "  results = run_hparam_search(EXPERIMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558494e",
   "metadata": {},
   "source": [
    "\n",
    "## **0) Setup & contraintes (à exécuter en premier)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39c37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[limits] OMP/BLAS threads=2 | CUDA_VISIBLE_DEVICES=-1\n",
      "[limits] RLIMIT_AS: soft=8589934591GB hard=8589934591GB\n",
      "[limits] OMP/BLAS threads=2 | CUDA_VISIBLE_DEVICES=-1\n",
      "[limits] RLIMIT_AS: soft=8589934591GB hard=8589934591GB\n"
     ]
    }
   ],
   "source": [
    "# --- Imports de base (sans hack de sys.path) ---\n",
    "import os, sys, time, json, csv, random, itertools, importlib, inspect\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Callable, Iterable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Limites \"plateforme\" AVANT d'importer torch/numpy lourds si possible ---\n",
    "from permuted_mnist.limits_perf3 import apply_challenge_limits, print_limits\n",
    "apply_challenge_limits(threads=2, forbid_gpu=True, ram_gb=4, show=True)\n",
    "print_limits()\n",
    "\n",
    "# --- Environnement PermutedMNIST ---\n",
    "from permuted_mnist.env.permuted_mnist import PermutedMNISTEnv\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2182a8a",
   "metadata": {},
   "source": [
    "\n",
    "## **1) Fabrique d'agent générique**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54e82c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_agent_factory(agent_spec: Tuple[str, str],\n",
    "                       fixed_kwargs: Dict | None = None,\n",
    "                       seed: int = 42) -> Callable[[Dict], object]:\n",
    "    \"\"\"\n",
    "    Retourne une fonction make_agent(cfg) qui instancie l'agent défini par agent_spec\n",
    "    en filtrant automatiquement les kwargs non supportés par __init__ de la classe.\n",
    "    \"\"\"\n",
    "    if fixed_kwargs is None:\n",
    "        fixed_kwargs = {}\n",
    "\n",
    "    mod = importlib.import_module(agent_spec[0])\n",
    "    AgentCls = getattr(mod, agent_spec[1])\n",
    "\n",
    "    sig = inspect.signature(AgentCls.__init__)\n",
    "    allowed = set(sig.parameters.keys()) - {\"self\"}\n",
    "\n",
    "    def make_agent(cfg: Dict) -> object:\n",
    "        kw = dict(fixed_kwargs); kw.update(cfg)\n",
    "        # Valeurs par défaut utiles si absentes\n",
    "        kw.setdefault(\"seed\", seed)\n",
    "        kw.setdefault(\"output_dim\", 10)\n",
    "        # Filtrage automatique\n",
    "        kw = {k: v for k, v in kw.items() if k in allowed}\n",
    "        return AgentCls(**kw)\n",
    "\n",
    "    return make_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598268d",
   "metadata": {},
   "source": [
    "\n",
    "## **2) Génération d'espaces (grid) et utilitaires**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d23fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def product_space(space: Dict[str, Iterable]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    space: {\"param\": [v1, v2, ...], \"param2\": [...]}\n",
    "    -> liste de dicts (toutes les combinaisons, mélangées)\n",
    "    \"\"\"\n",
    "    keys = list(space.keys())\n",
    "    vals = [list(space[k]) for k in keys]\n",
    "    out = []\n",
    "    for combo in itertools.product(*vals):\n",
    "        out.append({k: v for k, v in zip(keys, combo)})\n",
    "    random.shuffle(out)\n",
    "    return out\n",
    "\n",
    "def pick_top(results: List[Dict], k: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Classement pénalisé: d'abord pénalité prune, puis -accuracy, puis temps moyen.\n",
    "    results: sorties de eval_cfg(...)\n",
    "    \"\"\"\n",
    "    def key(r):\n",
    "        pen = (1.0 if r[\"pruned_time\"] else 0.0) + (0.5 if r[\"pruned_acc\"] else 0.0)\n",
    "        return (pen, -r[\"mean_acc\"], r[\"mean_time\"])\n",
    "    return sorted(results, key=key)[:k]\n",
    "\n",
    "def save_phase_csv(path: Path, results: List[Dict], param_keys: List[str]):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        header = param_keys + [\"mean_acc\",\"std_acc\",\"mean_time\",\"total_time\",\"n_tasks\",\"pruned_time\",\"pruned_acc\"]\n",
    "        w.writerow(header)\n",
    "        for r in results:\n",
    "            row = [r[\"config\"].get(k, None) for k in param_keys]\n",
    "            row += [r[\"mean_acc\"], r[\"std_acc\"], r[\"mean_time\"], r[\"total_time\"], r[\"n_tasks\"],\n",
    "                    r[\"pruned_time\"], r[\"pruned_acc\"]]\n",
    "            w.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6debcb7e",
   "metadata": {},
   "source": [
    "\n",
    "## **3) Évaluation d'une config avec pruning (multi-tâches)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a33cab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cfg(cfg: Dict,\n",
    "             make_agent: Callable[[Dict], object],\n",
    "             env_tasks: int,\n",
    "             prune_rules: Dict,\n",
    "             seed: int = 42,\n",
    "             include_init_time: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    prune_rules attend:\n",
    "      {\n",
    "        \"time_budget_s\": 58.0,\n",
    "        \"time_factor_stop\": 1.20,     # stop si t_task > factor * budget\n",
    "        \"phase\": \"A\" / \"B\" / None,\n",
    "        \"A_first\": 0.970, \"A_mean\": 0.970,\n",
    "        \"B_first\": 0.980, \"B_mean\": 0.980\n",
    "      }\n",
    "    include_init_time:\n",
    "      - False: on mesure train+predict (comme avant)\n",
    "      - True : on mesure init+reset+train+predict (proche plateforme)\n",
    "    \"\"\"\n",
    "    env = PermutedMNISTEnv(number_episodes=env_tasks)\n",
    "    env.set_seed(seed)\n",
    "\n",
    "    accs, times = [], []\n",
    "    pruned_time = False\n",
    "    pruned_acc = False\n",
    "    phase = prune_rules.get(\"phase\", None)\n",
    "\n",
    "    t_id = 0\n",
    "    while True:\n",
    "        task = env.get_next_task()\n",
    "        if task is None:\n",
    "            break\n",
    "        t_id += 1\n",
    "\n",
    "        if include_init_time:\n",
    "            t0 = time.time()\n",
    "            agent = make_agent(cfg)     # on compte le coût d'instanciation\n",
    "            agent.reset()\n",
    "            t_start = t0\n",
    "        else:\n",
    "            agent = make_agent(cfg)\n",
    "            agent.reset()\n",
    "            t_start = time.time()\n",
    "\n",
    "        agent.train(task[\"X_train\"], task[\"y_train\"])\n",
    "        preds = agent.predict(task[\"X_test\"])\n",
    "        elapsed = time.time() - t_start\n",
    "\n",
    "        acc = env.evaluate(preds, task[\"y_test\"])\n",
    "        accs.append(acc)\n",
    "        times.append(elapsed)\n",
    "\n",
    "        # Pruning temps\n",
    "        if elapsed > prune_rules[\"time_factor_stop\"] * prune_rules[\"time_budget_s\"]:\n",
    "            pruned_time = True\n",
    "            break\n",
    "\n",
    "        # Pruning accuracy\n",
    "        if phase == \"A\":\n",
    "            if len(accs) == 1 and accs[0] < prune_rules[\"A_first\"]:\n",
    "                pruned_acc = True; break\n",
    "            if len(accs) >= 2 and np.mean(accs) < prune_rules[\"A_mean\"]:\n",
    "                pruned_acc = True; break\n",
    "        if phase == \"B\":\n",
    "            if len(accs) == 1 and accs[0] < prune_rules[\"B_first\"]:\n",
    "                pruned_acc = True; break\n",
    "            if len(accs) >= 2 and np.mean(accs) < prune_rules[\"B_mean\"]:\n",
    "                pruned_acc = True; break\n",
    "\n",
    "        if t_id >= env_tasks:\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"config\": cfg,\n",
    "        \"mean_acc\": float(np.mean(accs) if accs else 0.0),\n",
    "        \"std_acc\": float(np.std(accs) if accs else 0.0),\n",
    "        \"mean_time\": float(np.mean(times) if times else 0.0),\n",
    "        \"total_time\": float(np.sum(times)),\n",
    "        \"n_tasks\": len(accs),\n",
    "        \"pruned_time\": pruned_time,\n",
    "        \"pruned_acc\": pruned_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094486e",
   "metadata": {},
   "source": [
    "\n",
    "## **4) Orchestration d'une phase (A / B / C)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01a33a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_phase(label: str,\n",
    "              cfg_list: List[Dict],\n",
    "              make_agent: Callable[[Dict], object],\n",
    "              env_tasks: int,\n",
    "              prune_rules: Dict,\n",
    "              out_csv: Path | None = None,\n",
    "              param_keys: List[str] | None = None,\n",
    "              include_init_time: bool = False) -> List[Dict]:\n",
    "    print(f\"\\n=== Phase {label}: N={len(cfg_list)}, tasks={env_tasks}, phase={prune_rules.get('phase', None)} ===\")\n",
    "    results = []\n",
    "    for i, cfg in enumerate(cfg_list, 1):\n",
    "        r = eval_cfg(cfg,\n",
    "                     make_agent=make_agent,\n",
    "                     env_tasks=env_tasks,\n",
    "                     prune_rules=prune_rules,\n",
    "                     seed=SEED,\n",
    "                     include_init_time=include_init_time)\n",
    "        tag = \" PRUNE[T]\" if r[\"pruned_time\"] else (\" PRUNE[A]\" if r[\"pruned_acc\"] else \"\")\n",
    "        print(f\"[{label} {i}/{len(cfg_list)}] acc={r['mean_acc']:.4f}±{r['std_acc']:.4f} | \"\n",
    "              f\"t={r['mean_time']:.1f}s | tasks={r['n_tasks']}{tag}\")\n",
    "        results.append(r)\n",
    "    if out_csv and param_keys:\n",
    "        save_phase_csv(out_csv, results, param_keys)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce49bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## **5) Pipeline complet prêt à l'emploi (A -> B -> C)**\n",
    "\n",
    "def run_hparam_search(experiment: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    experiment = {\n",
    "        \"agent_spec\": (\"module.path\", \"AgentClass\"),\n",
    "        \"fixed_kwargs\": {\"time_budget_s\": 55.0, ...},   # kwargs fixes de l'Agent\n",
    "        \"search_space\": {...},                          # dict: param -> liste de valeurs\n",
    "        \"n_A\": 30, \"n_B_keep\": 8, \"n_C_keep\": 3,\n",
    "        \"tasks\": {\"A\": 3, \"B\": 6, \"C\": 10},\n",
    "        \"prune\": {\n",
    "            \"A\": {\"time_budget_s\": 58.0, \"time_factor_stop\": 1.20, \"phase\": \"A\",\n",
    "                  \"A_first\": 0.970, \"A_mean\": 0.970},\n",
    "            \"B\": {\"time_budget_s\": 58.0, \"time_factor_stop\": 1.20, \"phase\": \"B\",\n",
    "                  \"B_first\": 0.980, \"B_mean\": 0.980},\n",
    "            \"C\": {\"time_budget_s\": 58.0, \"time_factor_stop\": 1.20, \"phase\": None}\n",
    "        },\n",
    "        \"outdir\": Path(\".../experiments/run_X\"),\n",
    "        \"seed\": 42\n",
    "    }\n",
    "    \"\"\"\n",
    "    outdir = experiment[\"outdir\"]; outdir.mkdir(parents=True, exist_ok=True)\n",
    "    param_keys = list(experiment[\"search_space\"].keys())\n",
    "\n",
    "    # Fabrique d'agent\n",
    "    make_agent = make_agent_factory(\n",
    "        agent_spec=experiment[\"agent_spec\"],\n",
    "        fixed_kwargs=experiment.get(\"fixed_kwargs\", {}),\n",
    "        seed=experiment.get(\"seed\", 42)\n",
    "    )\n",
    "\n",
    "    # Espace Phase A\n",
    "    all_cfgs = product_space(experiment[\"search_space\"])\n",
    "    A_cfgs = all_cfgs[:experiment[\"n_A\"]]\n",
    "    A = run_phase(\"A\", A_cfgs, make_agent,\n",
    "                  env_tasks=experiment[\"tasks\"][\"A\"],\n",
    "                  prune_rules=experiment[\"prune\"][\"A\"],\n",
    "                  out_csv=outdir/\"phase_A.csv\", param_keys=param_keys)\n",
    "\n",
    "    # Sélection pour Phase B\n",
    "    B_cfgs = [r[\"config\"] for r in pick_top(A, experiment[\"n_B_keep\"])]\n",
    "    B = run_phase(\"B\", B_cfgs, make_agent,\n",
    "                  env_tasks=experiment[\"tasks\"][\"B\"],\n",
    "                  prune_rules=experiment[\"prune\"][\"B\"],\n",
    "                  out_csv=outdir/\"phase_B.csv\", param_keys=param_keys)\n",
    "\n",
    "    # Sélection pour Phase C\n",
    "    C_cfgs = [r[\"config\"] for r in pick_top(B, experiment[\"n_C_keep\"])]\n",
    "    C = run_phase(\"C\", C_cfgs, make_agent,\n",
    "                  env_tasks=experiment[\"tasks\"][\"C\"],\n",
    "                  prune_rules=experiment[\"prune\"][\"C\"],\n",
    "                  out_csv=outdir/\"phase_C.csv\", param_keys=param_keys)\n",
    "\n",
    "    final = sorted(C, key=lambda r: (-r[\"mean_acc\"], r[\"mean_time\"]))\n",
    "    with open(outdir/\"final_top.json\", \"w\") as f:\n",
    "        json.dump(final[:3], f, indent=2)\n",
    "\n",
    "    # Affichage compact du TOP-3\n",
    "    def _cfg_slice(r):\n",
    "        return {k: r['config'].get(k) for k in param_keys}\n",
    "    print(\"\\nTOP-3:\", [\n",
    "        (_cfg_slice(final[0]), final[0][\"mean_acc\"], final[0][\"mean_time\"]) if len(final)>0 else None,\n",
    "        (_cfg_slice(final[1]), final[1][\"mean_acc\"], final[1][\"mean_time\"]) if len(final)>1 else None,\n",
    "        (_cfg_slice(final[2]), final[2][\"mean_acc\"], final[2][\"mean_time\"]) if len(final)>2 else None,\n",
    "    ])\n",
    "\n",
    "    return {\"A\": A, \"B\": B, \"C\": C, \"final\": final}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c93e3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Phase A: N=30, tasks=3, phase=A ===\n",
      "[A 1/30] acc=0.9625±0.0006 | t=8.6s | tasks=2 PRUNE[A]\n",
      "[A 2/30] acc=0.9544±0.0000 | t=4.5s | tasks=1 PRUNE[A]\n",
      "[A 3/30] acc=0.9585±0.0000 | t=4.0s | tasks=1 PRUNE[A]\n",
      "[A 4/30] acc=0.9814±0.0007 | t=10.3s | tasks=3\n",
      "[A 5/30] acc=0.9826±0.0004 | t=12.5s | tasks=3\n",
      "[A 6/30] acc=0.9729±0.0003 | t=4.4s | tasks=3\n",
      "[A 7/30] acc=0.9672±0.0007 | t=5.0s | tasks=3\n",
      "[A 8/30] acc=0.9785±0.0004 | t=12.3s | tasks=3\n",
      "[A 9/30] acc=0.9721±0.0005 | t=3.2s | tasks=3\n",
      "[A 10/30] acc=0.9625±0.0005 | t=5.9s | tasks=2 PRUNE[A]\n",
      "[A 11/30] acc=0.9729±0.0004 | t=10.8s | tasks=3\n",
      "[A 12/30] acc=0.9621±0.0003 | t=7.7s | tasks=2 PRUNE[A]\n",
      "[A 13/30] acc=0.9801±0.0000 | t=3.2s | tasks=3\n",
      "[A 14/30] acc=0.9767±0.0006 | t=15.1s | tasks=3\n",
      "[A 15/30] acc=0.9741±0.0006 | t=9.8s | tasks=3\n",
      "[A 16/30] acc=0.9758±0.0003 | t=8.5s | tasks=3\n",
      "[A 17/30] acc=0.9776±0.0002 | t=10.0s | tasks=3\n",
      "[A 18/30] acc=0.9815±0.0002 | t=6.6s | tasks=3\n",
      "[A 19/30] acc=0.9688±0.0007 | t=11.0s | tasks=3\n",
      "[A 20/30] acc=0.9709±0.0004 | t=5.0s | tasks=3\n",
      "[A 21/30] acc=0.9716±0.0007 | t=15.1s | tasks=3\n",
      "[A 22/30] acc=0.9845±0.0008 | t=12.8s | tasks=3\n",
      "[A 23/30] acc=0.9727±0.0009 | t=6.8s | tasks=3\n",
      "[A 24/30] acc=0.9760±0.0010 | t=15.4s | tasks=3\n",
      "[A 25/30] acc=0.9823±0.0006 | t=12.7s | tasks=3\n",
      "[A 26/30] acc=0.9777±0.0001 | t=16.4s | tasks=3\n",
      "[A 27/30] acc=0.9627±0.0001 | t=3.8s | tasks=2 PRUNE[A]\n",
      "[A 28/30] acc=0.9646±0.0010 | t=4.9s | tasks=2 PRUNE[A]\n",
      "[A 29/30] acc=0.9656±0.0003 | t=5.9s | tasks=3\n",
      "[A 30/30] acc=0.9821±0.0008 | t=16.2s | tasks=3\n",
      "\n",
      "=== Phase B: N=8, tasks=6, phase=B ===\n",
      "[B 1/8] acc=0.9842±0.0008 | t=13.0s | tasks=6\n",
      "[B 2/8] acc=0.9824±0.0005 | t=12.8s | tasks=6\n",
      "[B 3/8] acc=0.9823±0.0005 | t=12.5s | tasks=6\n",
      "[B 4/8] acc=0.9823±0.0009 | t=16.4s | tasks=6\n",
      "[B 5/8] acc=0.9815±0.0001 | t=7.7s | tasks=6\n",
      "[B 6/8] acc=0.9808±0.0011 | t=11.1s | tasks=6\n",
      "[B 7/8] acc=0.9801±0.0003 | t=4.0s | tasks=6\n",
      "[B 8/8] acc=0.9787±0.0003 | t=12.8s | tasks=6\n",
      "\n",
      "=== Phase C: N=3, tasks=10, phase=None ===\n",
      "[C 1/3] acc=0.9842±0.0007 | t=12.7s | tasks=10\n",
      "[C 2/3] acc=0.9825±0.0005 | t=13.0s | tasks=10\n",
      "[C 3/3] acc=0.9822±0.0008 | t=17.6s | tasks=10\n",
      "\n",
      "TOP-3: [({'hidden': (1536,), 'dropout': 0.1, 'batch_size': 1024, 'learning_rate': 0.0015, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001}, 0.98425, 12.706830143928528), ({'hidden': (1536,), 'dropout': 0.05, 'batch_size': 1024, 'learning_rate': 0.001, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001}, 0.98246, 13.029538750648499), ({'hidden': (2048,), 'dropout': 0.1, 'batch_size': 2048, 'learning_rate': 0.0015, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001}, 0.9821899999999999, 17.628802251815795)]\n",
      "\n",
      "[1-LAYER] TOP-3 (tri = acc desc, puis temps asc)\n",
      "#1  cfg={'hidden': (1536,), 'dropout': 0.1, 'batch_size': 1024, 'learning_rate': 0.0015, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001}  |  acc=0.9842  |  t=12.7s\n",
      "#2  cfg={'hidden': (1536,), 'dropout': 0.05, 'batch_size': 1024, 'learning_rate': 0.001, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001}  |  acc=0.9825  |  t=13.0s\n",
      "#3  cfg={'hidden': (2048,), 'dropout': 0.1, 'batch_size': 2048, 'learning_rate': 0.0015, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001}  |  acc=0.9822  |  t=17.6s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# ============================================================\n",
    "# EXPÉRIMENTATION — MLP 1 couche cachée (hidden = (H,))\n",
    "# Agent cible : le même que d’habitude (simple MLP)\n",
    "# ============================================================\n",
    "\n",
    "# 1) Espace de recherche (1 seule couche)\n",
    "WIDTHS_1L = [512, 768, 1024, 1536, 2048]   # tu peux élargir/réduire\n",
    "DROPS     = [0.00, 0.05, 0.10]\n",
    "BATCHES   = [1024, 2048, 3072]\n",
    "LRS       = [1e-3, 1.2e-3, 1.5e-3]\n",
    "LSMOOTH   = [0.0, 0.05]\n",
    "\n",
    "SEARCH_SPACE_1L = {\n",
    "    \"hidden\": [(w,) for w in WIDTHS_1L],   # <-- 1 SEULE couche : tuple à 1 élément\n",
    "    \"dropout\": DROPS,\n",
    "    \"batch_size\": BATCHES,\n",
    "    \"learning_rate\": LRS,\n",
    "    \"label_smoothing\": LSMOOTH,\n",
    "    \"max_epochs\": [10],\n",
    "    \"val_fraction\": [0.10],\n",
    "    \"weight_decay\": [1e-4],\n",
    "}\n",
    "\n",
    "# 2) Règles de pruning un peu plus souples pour Phase A (modèles simples)\n",
    "PRUNE_RULES_1L = {\n",
    "    \"A\": {\"time_budget_s\": 58.0, \"time_factor_stop\": 1.20, \"phase\": \"A\",\n",
    "          \"A_first\": 0.960, \"A_mean\": 0.965},      # <-- un poil plus bas que 2-couches\n",
    "    \"B\": {\"time_budget_s\": 58.0, \"time_factor_stop\": 1.20, \"phase\": \"B\",\n",
    "          \"B_first\": 0.975, \"B_mean\": 0.978},      # <-- on resserre en phase B\n",
    "    \"C\": {\"time_budget_s\": 58.0, \"time_factor_stop\": 1.20, \"phase\": None}\n",
    "}\n",
    "\n",
    "# 3) Choix de l’agent\n",
    "# - si tu veux tester ton simple MLP générique :\n",
    "AGENT_SPEC_1L = (\"permuted_mnist.agent_r1.agent_mlp_v3\", \"Agent\")\n",
    "# - ou une autre implémentation mono-couche compatible si tu en as une :\n",
    "# AGENT_SPEC_1L = (\"permuted_mnist.agent.mlp4.agent_Bruce_Wayne\", \"Agent\")\n",
    "\n",
    "# 4) Définition de l’expérience 1-couche\n",
    "EXPERIMENT_1L = {\n",
    "    \"agent_spec\": AGENT_SPEC_1L,\n",
    "    \"fixed_kwargs\": {\n",
    "        \"time_budget_s\": 55.0,   # marge vs 60 s plateforme\n",
    "        \"output_dim\": 10,\n",
    "        \"seed\": 42\n",
    "    },\n",
    "    \"search_space\": SEARCH_SPACE_1L,\n",
    "    \"n_A\": 30,          # nb de configs max en Phase A\n",
    "    \"n_B_keep\": 8,      # on retient les 8 meilleures pour B\n",
    "    \"n_C_keep\": 3,      # on retient les 3 meilleures pour C\n",
    "    \"tasks\": {\"A\": 3, \"B\": 6, \"C\": 10},\n",
    "    \"prune\": PRUNE_RULES_1L,\n",
    "    \"outdir\": Path(\"../experiments/hparam_1layer\"),\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# 5) Lancer la recherche\n",
    "results_1L = run_hparam_search(EXPERIMENT_1L)\n",
    "\n",
    "# 6) Petit affichage confort : récap rapide des TOP-3\n",
    "final_1L = results_1L[\"final\"]\n",
    "print(\"\\n[1-LAYER] TOP-3 (tri = acc desc, puis temps asc)\")\n",
    "for i, r in enumerate(sorted(final_1L, key=lambda x: (-x[\"mean_acc\"], x[\"mean_time\"]))[:3], 1):\n",
    "    print(f\"#{i}  cfg={r['config']}  |  acc={r['mean_acc']:.4f}  |  t={r['mean_time']:.1f}s\")\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5cf68cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Phase A: N=30, tasks=3, phase=A ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 129\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m: A, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m: B, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m: C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m\"\u001b[39m: final}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# 5) Lancer la recherche 1-couche\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m results_1L \u001b[38;5;241m=\u001b[39m \u001b[43mrun_hparam_search_with_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEXPERIMENT_1L\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# 6) Affichage TOP-3 propre\u001b[39;00m\n\u001b[1;32m    132\u001b[0m final_1L \u001b[38;5;241m=\u001b[39m results_1L[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[26], line 102\u001b[0m, in \u001b[0;36mrun_hparam_search_with_init\u001b[0;34m(experiment)\u001b[0m\n\u001b[1;32m    100\u001b[0m all_cfgs \u001b[38;5;241m=\u001b[39m product_space(experiment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_space\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    101\u001b[0m A_cfgs \u001b[38;5;241m=\u001b[39m all_cfgs[:experiment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_A\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m--> 102\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mrun_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_cfgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m              \u001b[49m\u001b[43menv_tasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtasks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m              \u001b[49m\u001b[43mprune_rules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprune\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m              \u001b[49m\u001b[43mout_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutdir\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphase_A.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m              \u001b[49m\u001b[43minclude_init_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m B_cfgs \u001b[38;5;241m=\u001b[39m [r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m pick_top(A, experiment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_B_keep\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\n\u001b[1;32m    109\u001b[0m B \u001b[38;5;241m=\u001b[39m run_phase(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, B_cfgs, make_agent,\n\u001b[1;32m    110\u001b[0m               env_tasks\u001b[38;5;241m=\u001b[39mexperiment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtasks\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    111\u001b[0m               prune_rules\u001b[38;5;241m=\u001b[39mexperiment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprune\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    112\u001b[0m               out_csv\u001b[38;5;241m=\u001b[39moutdir\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphase_B.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, param_keys\u001b[38;5;241m=\u001b[39mparam_keys,\n\u001b[1;32m    113\u001b[0m               include_init_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[24], line 12\u001b[0m, in \u001b[0;36mrun_phase\u001b[0;34m(label, cfg_list, make_agent, env_tasks, prune_rules, out_csv, param_keys, include_init_time)\u001b[0m\n\u001b[1;32m     10\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, cfg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cfg_list, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43meval_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmake_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                 \u001b[49m\u001b[43menv_tasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_tasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mprune_rules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprune_rules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                 \u001b[49m\u001b[43minclude_init_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_init_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m PRUNE[T]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpruned_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m PRUNE[A]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpruned_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cfg_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m±\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms | tasks=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_tasks\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 45\u001b[0m, in \u001b[0;36meval_cfg\u001b[0;34m(cfg, make_agent, env_tasks, prune_rules, seed, include_init_time)\u001b[0m\n\u001b[1;32m     42\u001b[0m     agent\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     43\u001b[0m     t_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 45\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m preds \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mpredict(task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_test\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     47\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n",
      "File \u001b[0;32m~/Desktop/Data_science_Data_challenge/permuted_mnist/permuted_mnist/agent_r1/agent_mlp_v3.py:110\u001b[0m, in \u001b[0;36mAgent.train\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m    108\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m X_tr[b], y_tr[b]\n\u001b[1;32m    109\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 110\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(logits, yb)\n\u001b[1;32m    112\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1426\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EXPÉRIMENTATION — MLP 1 couche cachée (hidden = (H,))\n",
    "# ============================================================\n",
    "\n",
    "# 0) Choisis l’agent à tester (doit accepter hidden=(H,), dropout, batch_size, learning_rate, etc.)\n",
    "#    - agent_mlp_v3 : MLP générique (ReLU), compatible 1-couche\n",
    "#    - agent_Bruce_Wayne : ton agent rapide (ReLU), compatible 1-couche\n",
    "AGENT_SPEC_1L = (\"permuted_mnist.agent_r1.agent_mlp_v3\", \"Agent\")\n",
    "# AGENT_SPEC_1L = (\"permuted_mnist.agent.mlp4.agent_Bruce_Wayne\", \"Agent\")\n",
    "\n",
    "# 1) Presets d’espace de recherche (tu peux en ajouter d’autres)\n",
    "def preset_search_space_1L(mode: str = \"quick\"):\n",
    "    \"\"\"\n",
    "    mode in {\"sanity\", \"quick\", \"full\"} :\n",
    "      - sanity : 4–6 configs pour valider le pipeline\n",
    "      - quick  : ~40–60 configs pour un vrai screening\n",
    "      - full   : ~100+ configs (plus long)\n",
    "    Toutes les configs sont mono-couche: hidden=(H,)\n",
    "    \"\"\"\n",
    "    if mode == \"sanity\":\n",
    "        WIDTHS = [512, 1024]                   # petit éventail\n",
    "        DROPS  = [0.00, 0.05]\n",
    "        BATCH  = [1024, 2048]\n",
    "        LRS    = [1e-3]\n",
    "        LSM    = [0.0, 0.05]\n",
    "    elif mode == \"quick\":\n",
    "        WIDTHS = [512, 768, 1024, 1536, 2048]  # large mais raisonnable\n",
    "        DROPS  = [0.00, 0.05, 0.10]\n",
    "        BATCH  = [1024, 2048, 3072]\n",
    "        LRS    = [1e-3, 1.2e-3, 1.5e-3]\n",
    "        LSM    = [0.0, 0.05]\n",
    "    elif mode == \"full\":\n",
    "        WIDTHS = [384, 512, 768, 1024, 1280, 1536, 1792, 2048]\n",
    "        DROPS  = [0.00, 0.05, 0.10, 0.15]\n",
    "        BATCH  = [1024, 1536, 2048, 2560, 3072]\n",
    "        LRS    = [8e-4, 1e-3, 1.2e-3, 1.5e-3]\n",
    "        LSM    = [0.0, 0.05]\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'sanity', 'quick' or 'full'.\")\n",
    "\n",
    "    return {\n",
    "        \"hidden\": [(w,) for w in WIDTHS],   # MONO-COUCHE: tuple à 1 élément\n",
    "        \"dropout\": DROPS,\n",
    "        \"batch_size\": BATCH,\n",
    "        \"learning_rate\": LRS,\n",
    "        \"label_smoothing\": LSM,\n",
    "        \"max_epochs\": [10],                 # garde 10 ep. cohérent avec tes agents\n",
    "        \"val_fraction\": [0.10],\n",
    "        \"weight_decay\": [1e-4],\n",
    "    }\n",
    "\n",
    "# 2) Règles de pruning (un peu plus souples en Phase A pour 1-couche)\n",
    "PRUNE_RULES_1L = {\n",
    "    \"A\": {\"time_budget_s\": 58.0, \"time_factor_stop\": 1.20, \"phase\": \"A\",\n",
    "          \"A_first\": 0.960, \"A_mean\": 0.965},\n",
    "    \"B\": {\"time_budget_s\": 58.0, \"time_factor_stop\": 1.20, \"phase\": \"B\",\n",
    "          \"B_first\": 0.975, \"B_mean\": 0.978},\n",
    "    \"C\": {\"time_budget_s\": 58.0, \"time_factor_stop\": 1.20, \"phase\": None}\n",
    "}\n",
    "\n",
    "# 3) Fabrique l’expérience à partir d’un preset et lance\n",
    "def make_experiment_1L(agent_spec, search_mode: str, outdir: Path) -> dict:\n",
    "    space = preset_search_space_1L(search_mode)\n",
    "    return {\n",
    "        \"agent_spec\": agent_spec,\n",
    "        \"fixed_kwargs\": {\n",
    "            \"time_budget_s\": 55.0,   # marge vs 60 s plateforme\n",
    "            \"output_dim\": 10,\n",
    "            \"seed\": 42\n",
    "        },\n",
    "        \"search_space\": space,\n",
    "        # Taille des phases (tu peux augmenter pour \"full\")\n",
    "        \"n_A\": 30 if search_mode != \"sanity\" else 6,\n",
    "        \"n_B_keep\": 8 if search_mode != \"sanity\" else 3,\n",
    "        \"n_C_keep\": 3 if search_mode != \"sanity\" else 2,\n",
    "        \"tasks\": {\"A\": 3, \"B\": 6, \"C\": 10},\n",
    "        \"prune\": PRUNE_RULES_1L,\n",
    "        \"outdir\": outdir,\n",
    "        \"seed\": 42\n",
    "    }\n",
    "\n",
    "# 4) Choix du preset et lancement\n",
    "SEARCH_MODE = \"quick\"   # \"sanity\" | \"quick\" | \"full\"\n",
    "OUTDIR_1L = Path(\"../experiments/hparam_1layer\") / SEARCH_MODE\n",
    "\n",
    "EXPERIMENT_1L = make_experiment_1L(AGENT_SPEC_1L, SEARCH_MODE, OUTDIR_1L)\n",
    "\n",
    "# IMPORTANT : mesure proche plateforme (inclure l’instanciation)\n",
    "# -> on redéfinit run_hparam_search pour passer include_init_time=True à run_phase\n",
    "def run_hparam_search_with_init(experiment: Dict) -> Dict:\n",
    "    outdir = experiment[\"outdir\"]; outdir.mkdir(parents=True, exist_ok=True)\n",
    "    param_keys = list(experiment[\"search_space\"].keys())\n",
    "\n",
    "    make_agent = make_agent_factory(\n",
    "        agent_spec=experiment[\"agent_spec\"],\n",
    "        fixed_kwargs=experiment.get(\"fixed_kwargs\", {}),\n",
    "        seed=experiment.get(\"seed\", 42)\n",
    "    )\n",
    "\n",
    "    all_cfgs = product_space(experiment[\"search_space\"])\n",
    "    A_cfgs = all_cfgs[:experiment[\"n_A\"]]\n",
    "    A = run_phase(\"A\", A_cfgs, make_agent,\n",
    "                  env_tasks=experiment[\"tasks\"][\"A\"],\n",
    "                  prune_rules=experiment[\"prune\"][\"A\"],\n",
    "                  out_csv=outdir/\"phase_A.csv\", param_keys=param_keys,\n",
    "                  include_init_time=True)\n",
    "\n",
    "    B_cfgs = [r[\"config\"] for r in pick_top(A, experiment[\"n_B_keep\"])]\n",
    "    B = run_phase(\"B\", B_cfgs, make_agent,\n",
    "                  env_tasks=experiment[\"tasks\"][\"B\"],\n",
    "                  prune_rules=experiment[\"prune\"][\"B\"],\n",
    "                  out_csv=outdir/\"phase_B.csv\", param_keys=param_keys,\n",
    "                  include_init_time=True)\n",
    "\n",
    "    C_cfgs = [r[\"config\"] for r in pick_top(B, experiment[\"n_C_keep\"])]\n",
    "    C = run_phase(\"C\", C_cfgs, make_agent,\n",
    "                  env_tasks=experiment[\"tasks\"][\"C\"],\n",
    "                  prune_rules=experiment[\"prune\"][\"C\"],\n",
    "                  out_csv=outdir/\"phase_C.csv\", param_keys=param_keys,\n",
    "                  include_init_time=True)\n",
    "\n",
    "    final = sorted(C, key=lambda r: (-r[\"mean_acc\"], r[\"mean_time\"]))\n",
    "    with open(outdir/\"final_top.json\", \"w\") as f:\n",
    "        json.dump(final[:3], f, indent=2)\n",
    "\n",
    "    return {\"A\": A, \"B\": B, \"C\": C, \"final\": final}\n",
    "\n",
    "# 5) Lancer la recherche 1-couche\n",
    "results_1L = run_hparam_search_with_init(EXPERIMENT_1L)\n",
    "\n",
    "# 6) Affichage TOP-3 propre\n",
    "final_1L = results_1L[\"final\"]\n",
    "print(\"\\n[1-LAYER] TOP-3 (tri = acc desc, puis temps asc)\")\n",
    "for i, r in enumerate(sorted(final_1L, key=lambda x: (-x[\"mean_acc\"], x[\"mean_time\"]))[:3], 1):\n",
    "    print(f\"#{i}  cfg={r['config']}  |  acc={r['mean_acc']:.4f}  |  t={r['mean_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b720d52a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No phase CSV found. Run the search phases first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m         dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo phase CSV found. Run the search phases first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m res \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Normalize types: ensure hyperparams are strings if tuples\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No phase CSV found. Run the search phases first."
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# 7) Post-hoc analysis: What drives performance?\n",
    "# ================================================\n",
    "import json, ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- Paths to phase CSVs (adjust if needed) ----\n",
    "PHASE_DIR = Path(\"../experiments/phased_modular\")  # or your OUT dir\n",
    "phase_files = [PHASE_DIR/\"phase_A.csv\", PHASE_DIR/\"phase_B.csv\", PHASE_DIR/\"phase_C.csv\"]\n",
    "\n",
    "# --------- 7.1 Load & unify results ----------\n",
    "dfs = []\n",
    "for p in phase_files:\n",
    "    if p.exists():\n",
    "        df = pd.read_csv(p)\n",
    "        df[\"phase_file\"] = p.name\n",
    "        dfs.append(df)\n",
    "if not dfs:\n",
    "    raise RuntimeError(\"No phase CSV found. Run the search phases first.\")\n",
    "res = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Normalize types: ensure hyperparams are strings if tuples\n",
    "def _canonicalize_hidden(x):\n",
    "    # x might be like \"(2048, 1024)\" string; parse then re-string cleanly\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            t = ast.literal_eval(x)\n",
    "            if isinstance(t, (list, tuple)):\n",
    "                return str(tuple(int(v) for v in t))\n",
    "        except Exception:\n",
    "            pass\n",
    "        return x\n",
    "    if isinstance(x, (list, tuple, np.ndarray)):\n",
    "        return str(tuple(int(v) for v in x))\n",
    "    return str(x)\n",
    "\n",
    "if \"hidden\" in res.columns:\n",
    "    res[\"hidden\"] = res[\"hidden\"].apply(_canonicalize_hidden)\n",
    "\n",
    "# Ensure numeric dtypes\n",
    "for c in [\"dropout\",\"batch_size\",\"learning_rate\",\"label_smoothing\",\n",
    "          \"mean_acc\",\"std_acc\",\"mean_time\",\"total_time\"]:\n",
    "    if c in res.columns:\n",
    "        res[c] = pd.to_numeric(res[c], errors=\"coerce\")\n",
    "\n",
    "# A small helper: time-budget compliance at 60s total per task (use your effective budget)\n",
    "BUDGET_S = 60.0\n",
    "res[\"ok_time\"] = (res[\"mean_time\"] <= BUDGET_S).astype(int)\n",
    "\n",
    "print(\"Merged results shape:\", res.shape)\n",
    "display(res.head(10))\n",
    "\n",
    "# --------- 7.2 Marginal effects per hyperparameter ----------\n",
    "def summarize_marginal_effect(df, param, metric=\"mean_acc\"):\n",
    "    g = df.groupby(param)[metric]\n",
    "    out = (g.mean().rename(\"mean\")\n",
    "             .to_frame()\n",
    "             .join(g.std().rename(\"std\"))\n",
    "             .join(g.count().rename(\"n\")))\n",
    "    # 95% CI on the mean (normal approx); safe for large n\n",
    "    out[\"se\"] = out[\"std\"] / np.sqrt(out[\"n\"].clip(lower=1))\n",
    "    out[\"ci95_low\"] = out[\"mean\"] - 1.96 * out[\"se\"]\n",
    "    out[\"ci95_high\"] = out[\"mean\"] + 1.96 * out[\"se\"]\n",
    "    return out.sort_values(\"mean\", ascending=False)\n",
    "\n",
    "candidate_params = [c for c in [\"hidden\",\"dropout\",\"batch_size\",\"learning_rate\",\"label_smoothing\"] if c in res.columns]\n",
    "\n",
    "marginals = {}\n",
    "for p in candidate_params:\n",
    "    marginals[p] = summarize_marginal_effect(res, p, metric=\"mean_acc\")\n",
    "\n",
    "print(\"\\n--- Marginal effects on accuracy (mean±CI) ---\")\n",
    "for p in candidate_params:\n",
    "    print(f\"\\n[{p}]\")\n",
    "    display(marginals[p])\n",
    "\n",
    "# Plot marginal bars for each param\n",
    "for p in candidate_params:\n",
    "    m = marginals[p]\n",
    "    plt.figure()\n",
    "    m[\"mean\"].plot(kind=\"barh\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"Mean Accuracy\")\n",
    "    plt.title(f\"Marginal accuracy by {p}\")\n",
    "    plt.show()\n",
    "\n",
    "# --------- 7.3 Pairwise heatmaps (accuracy) ----------\n",
    "def heatmap_param2(df, p1, p2, metric=\"mean_acc\"):\n",
    "    pivot = pd.pivot_table(df, index=p1, columns=p2, values=metric, aggfunc=np.mean)\n",
    "    plt.figure()\n",
    "    plt.imshow(pivot.values, aspect=\"auto\")\n",
    "    plt.xticks(range(pivot.shape[1]), pivot.columns, rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(pivot.shape[0]), pivot.index)\n",
    "    plt.title(f\"{metric} heatmap: {p1} × {p2}\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return pivot\n",
    "\n",
    "pairs = []\n",
    "# choose a few useful pairs if present\n",
    "if \"hidden\" in res.columns and \"learning_rate\" in res.columns:\n",
    "    pairs.append((\"hidden\",\"learning_rate\"))\n",
    "if \"hidden\" in res.columns and \"dropout\" in res.columns:\n",
    "    pairs.append((\"hidden\",\"dropout\"))\n",
    "if \"batch_size\" in res.columns and \"learning_rate\" in res.columns:\n",
    "    pairs.append((\"batch_size\",\"learning_rate\"))\n",
    "\n",
    "for p1, p2 in pairs:\n",
    "    pivot = heatmap_param2(res, p1, p2, metric=\"mean_acc\")\n",
    "    display(pivot)\n",
    "\n",
    "# --------- 7.4 Simple linear model on one-hot features (effect sizes) ----------\n",
    "# Build X with one-hot encoding for categorical-ish features, numeric for continuous\n",
    "use_cols = []\n",
    "X_parts = []\n",
    "for p in candidate_params:\n",
    "    if res[p].dtype.kind in \"ifu\":  # numeric\n",
    "        X_parts.append(((res[p] - res[p].mean()) / (res[p].std() + 1e-9)).to_frame(p))\n",
    "        use_cols.append(p)\n",
    "    else:\n",
    "        # one-hot\n",
    "        d = pd.get_dummies(res[p], prefix=p)\n",
    "        # standardize columns for comparability\n",
    "        d = (d - d.values.mean()) / (d.values.std() + 1e-9)\n",
    "        X_parts.append(pd.DataFrame(d, index=res.index))\n",
    "        use_cols.extend(d.columns.tolist())\n",
    "\n",
    "X = pd.concat(X_parts, axis=1)\n",
    "y = res[\"mean_acc\"].fillna(res[\"mean_acc\"].mean())\n",
    "\n",
    "# Ridge-like closed form with small L2 to stabilize: beta = (X^T X + λI)^(-1) X^T y\n",
    "lam = 1e-3\n",
    "XtX = X.values.T @ X.values\n",
    "beta = np.linalg.solve(XtX + lam*np.eye(XtX.shape[0]), X.values.T @ y.values)\n",
    "coef = pd.Series(beta, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n--- Standardized linear-effect sizes on accuracy (higher => stronger positive association) ---\")\n",
    "display(coef.head(20))\n",
    "print(\"\\n--- Most negative effects ---\")\n",
    "display(coef.tail(20))\n",
    "\n",
    "# --------- 7.5 Permutation importance on the linear model ----------\n",
    "def permutation_importance_linear(X_df, y_vec, beta_vec, n_repeats=10, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    base_pred = X_df.values @ beta_vec\n",
    "    base_mse = np.mean((y_vec.values - base_pred)**2)\n",
    "    imps = {}\n",
    "    for col in X_df.columns:\n",
    "        losses = []\n",
    "        for _ in range(n_repeats):\n",
    "            x_perm = X_df.copy()\n",
    "            x_perm[col] = x_perm[col].sample(frac=1.0, random_state=int(rng.integers(1e9))).values\n",
    "            pred = x_perm.values @ beta_vec\n",
    "            losses.append(np.mean((y_vec.values - pred)**2))\n",
    "        imps[col] = np.mean(losses) - base_mse\n",
    "    s = pd.Series(imps).sort_values(ascending=False)\n",
    "    return s\n",
    "\n",
    "perm_imp = permutation_importance_linear(X, y, beta, n_repeats=20)\n",
    "print(\"\\n--- Permutation importance (ΔMSE; higher = more important) ---\")\n",
    "display(perm_imp.head(20))\n",
    "\n",
    "plt.figure()\n",
    "perm_imp.head(20).plot(kind=\"barh\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Δ MSE on linear surrogate\")\n",
    "plt.title(\"Permutation importance (top 20 features)\")\n",
    "plt.show()\n",
    "\n",
    "# --------- 7.6 Time/accuracy trade-off and budget compliance ----------\n",
    "if \"mean_time\" in res.columns:\n",
    "    # Compliance rate per config key\n",
    "    print(\"\\n--- Time budget compliance by parameter level (ok_time=mean_time ≤ 60s) ---\")\n",
    "    for p in candidate_params:\n",
    "        grp = res.groupby(p)[\"ok_time\"].mean().sort_values(ascending=False)\n",
    "        print(f\"\\n[{p}]\")\n",
    "        display(grp)\n",
    "\n",
    "    # Pareto front (accuracy vs time)\n",
    "    df_at = res[[\"mean_acc\",\"mean_time\"]].dropna().copy()\n",
    "    df_at = df_at.sort_values([\"mean_time\",\"mean_acc\"])\n",
    "    pareto_idx = []\n",
    "    best_acc = -np.inf\n",
    "    for i, row in df_at.iterrows():\n",
    "        if row[\"mean_acc\"] > best_acc:\n",
    "            pareto_idx.append(i)\n",
    "            best_acc = row[\"mean_acc\"]\n",
    "    pareto = df_at.loc[pareto_idx]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(res[\"mean_time\"], res[\"mean_acc\"], s=18)\n",
    "    plt.plot(pareto[\"mean_time\"], pareto[\"mean_acc\"])\n",
    "    plt.xlabel(\"Mean time per task (s)\")\n",
    "    plt.ylabel(\"Mean accuracy\")\n",
    "    plt.title(\"Accuracy vs Time (Pareto front)\")\n",
    "    plt.show()\n",
    "\n",
    "# --------- 7.7 Compact textual takeaways ----------\n",
    "def top_levels(summary_dict, k=3):\n",
    "    for p, dfp in summary_dict.items():\n",
    "        best = dfp.head(k)[[\"mean\",\"ci95_low\",\"ci95_high\",\"n\"]]\n",
    "        print(f\"[{p}] top-{k} levels by accuracy mean:\")\n",
    "        print(best.to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "        print()\n",
    "\n",
    "print(\"\\n=== Quick takeaways (top-3 levels per parameter) ===\")\n",
    "top_levels(marginals, k=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
