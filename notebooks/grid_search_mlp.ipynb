{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "623c7b86",
   "metadata": {},
   "source": [
    "# **Recherche d’hyperparamètres - Stratégie structurée et contrainte**\n",
    "\n",
    "## **1. Objectif général**\n",
    "Concevoir une **recherche d’hyperparamètres rigoureuse, efficace et reproductible** pour les agents du challenge *Permuted MNIST*, sous fortes contraintes matérielles et temporelles.  \n",
    "L’approche repose sur une **méthodologie progressive et modulaire**, structurée autour de trois phases d’évaluation (A → B → C) avec **pruning adaptatif**.  \n",
    "Elle vise à trouver le meilleur compromis entre **précision, stabilité et efficacité CPU**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Contexte et contraintes**\n",
    "- **CPU-only**, 2 threads maximum  \n",
    "- **Mémoire ≤ 4 Go**  \n",
    "- **Temps d’exécution ≤ 60 s / task** (init + train + test)\n",
    "\n",
    "Ces contraintes excluent l’usage de modèles lourds (CNN, transformers) et motivent l’emploi d’**architectures MLP légères et optimisées CPU**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Philosophie de la recherche**\n",
    "1. Définir un **espace de recherche** pertinent centré sur les hyperparamètres influents.  \n",
    "2. Explorer progressivement trois phases d’évaluation (A, B, C) de complexité croissante.  \n",
    "3. Éliminer rapidement les modèles faibles grâce à un **pruning adaptatif**.  \n",
    "4. Enregistrer systématiquement les résultats (CSV + JSON) pour assurer traçabilité et analyse.\n",
    "\n",
    "Cette démarche reproduit une **approche scientifique contrôlée** : hypothèses → tests → validation.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Structure de la démarche**\n",
    "\n",
    "| Phase | Objectif | # Tasks | Pruning | Description |\n",
    "|:------|:----------|:--------|:---------|:-------------|\n",
    "| **A — Exploration large** | Identifier les tendances globales | 3 | Oui | Sélection initiale rapide. |\n",
    "| **B — Raffinement** | Confirmer les meilleures configs | 6 | Oui | Seuils plus stricts, meilleure stabilité. |\n",
    "| **C — Validation finale** | Évaluer la robustesse | 10 | Non | Estimation finale (moyenne et écart-type). |\n",
    "\n",
    "Chaque phase produit un rapport `.csv` et un résumé `.json`.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Architecture générale du pipeline**\n",
    "\n",
    "Le pipeline repose sur quatre briques fondamentales :\n",
    "\n",
    "| Brique | Rôle |\n",
    "|:-------|:-----|\n",
    "| **make_agent_factory** | Crée dynamiquement une fonction `make_agent(cfg)` à partir d’un module et d’une classe. |\n",
    "| **eval_cfg** | Évalue une configuration sur plusieurs tasks avec règles de pruning (temps et accuracy). |\n",
    "| **run_phase** | Exécute une phase (A/B/C), agrège les résultats et écrit un CSV. |\n",
    "| **run_hparam_search** | Orchestration complète : A → B → C + tri des meilleurs modèles. |\n",
    "\n",
    "Des fonctions utilitaires complètent le pipeline :\n",
    "- `product_space` : génère toutes les combinaisons d’un espace de recherche.  \n",
    "- `pick_top` : sélectionne les meilleures configurations.  \n",
    "- `save_phase_csv` : sauvegarde les résultats intermédiaires.  \n",
    "\n",
    "Enfin, des **builders** permettent de déclarer rapidement des espaces et règles cohérents :\n",
    "- `hidden_from_lists`, `grid_MLP`\n",
    "- `preset_tasks`, `preset_pruning`\n",
    "- `make_experiment`, `run_and_report`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c04ea15",
   "metadata": {},
   "source": [
    "\n",
    "## **0) Setup & contraintes (à exécuter en premier)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b52e28",
   "metadata": {},
   "source": [
    "\n",
    "Cette première section initialise l’environnement du challenge et applique les contraintes d’exécution :\n",
    "\n",
    "- **CPU-only**, 2 threads maximum  \n",
    "- **Mémoire ≤ 4 Go**  \n",
    "- **Temps ≤ 60 secondes** par task (initialisation + entraînement + test)\n",
    "\n",
    "Le bloc ci-dessous :\n",
    "1. importe les bibliothèques nécessaires,  \n",
    "2. applique les limites matérielles du challenge,  \n",
    "3. initialise la graine aléatoire,  \n",
    "4. et charge l’environnement `PermutedMNISTEnv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b293e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[limits] OMP/BLAS threads=2 | CUDA_VISIBLE_DEVICES=-1\n",
      "[limits] RLIMIT_AS: soft=8589934591GB hard=8589934591GB\n",
      "[limits] OMP/BLAS threads=2 | CUDA_VISIBLE_DEVICES=-1\n",
      "[limits] RLIMIT_AS: soft=8589934591GB hard=8589934591GB\n"
     ]
    }
   ],
   "source": [
    "# --- Imports de base (sans hack de sys.path) ---\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    base_path = os.path.dirname(__file__)\n",
    "except NameError:\n",
    "    base_path = os.getcwd()\n",
    "\n",
    "# 1️⃣ Ajouter le dossier parent (un cran au-dessus)\n",
    "parent_dir = os.path.abspath(os.path.join(base_path, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# 2️⃣ Ajouter le dossier parent du dossier parent (deux crans au-dessus)\n",
    "two_up_dir = os.path.abspath(os.path.join(base_path, '..', '..'))\n",
    "sys.path.append(two_up_dir)\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Import the environment and agents\n",
    "from permuted_mnist.env.permuted_mnist import PermutedMNISTEnv\n",
    "\n",
    "import json, csv, random, itertools, importlib, inspect\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Callable, Iterable\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e49d30e",
   "metadata": {},
   "source": [
    "\n",
    "## **1) Fabrique d'agent générique**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee9df60",
   "metadata": {},
   "source": [
    "**Objectif :** instancier dynamiquement un agent à partir de son module et de sa classe,  \n",
    "sans modifier le reste du pipeline.\n",
    "\n",
    "Cette fonction :\n",
    "- charge dynamiquement un agent via `importlib`,\n",
    "- filtre automatiquement les paramètres non supportés dans `__init__`,\n",
    "- insère les valeurs par défaut (`seed`, `output_dim`),\n",
    "- et renvoie une fonction `make_agent(cfg)` prête à l’emploi.\n",
    "\n",
    "C’est la brique qui permet de tester différents agents sans changer la logique du pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c779e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_agent_factory(agent_spec: Tuple[str, str],\n",
    "                       fixed_kwargs: Dict | None = None,\n",
    "                       seed: int = 42) -> Callable[[Dict], object]:\n",
    "    \"\"\"\n",
    "    Retourne une fonction make_agent(cfg) qui instancie l'agent défini par agent_spec\n",
    "    en filtrant automatiquement les kwargs non supportés par __init__ de la classe.\n",
    "    \"\"\"\n",
    "    if fixed_kwargs is None:\n",
    "        fixed_kwargs = {}\n",
    "\n",
    "    mod = importlib.import_module(agent_spec[0])\n",
    "    AgentCls = getattr(mod, agent_spec[1])\n",
    "\n",
    "    sig = inspect.signature(AgentCls.__init__)\n",
    "    allowed = set(sig.parameters.keys()) - {\"self\"}\n",
    "\n",
    "    def make_agent(cfg: Dict) -> object:\n",
    "        kw = dict(fixed_kwargs); kw.update(cfg)\n",
    "        # Valeurs par défaut utiles si absentes\n",
    "        kw.setdefault(\"seed\", seed)\n",
    "        kw.setdefault(\"output_dim\", 10)\n",
    "        # Filtrage automatique\n",
    "        kw = {k: v for k, v in kw.items() if k in allowed}\n",
    "        return AgentCls(**kw)\n",
    "\n",
    "    return make_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2cce8",
   "metadata": {},
   "source": [
    "\n",
    "## **2) Génération d'espaces (grid) et utilitaires**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1b3884",
   "metadata": {},
   "source": [
    "Ces fonctions gèrent la création, la sélection et la sauvegarde des configurations testées :\n",
    "\n",
    "- **`product_space(space)`** : transforme un dictionnaire `{param: [valeurs...]}`  \n",
    "  en liste de combinaisons d’hyperparamètres.\n",
    "- **`pick_top(results, k)`** : trie les résultats selon un score pénalisé  \n",
    "  (temps et pruning, puis accuracy).\n",
    "- **`save_phase_csv(...)`** : sauvegarde les résultats d’une phase au format CSV  \n",
    "  pour permettre l’audit et la traçabilité.\n",
    "\n",
    "Ces briques rendent la recherche systématique, reproductible et analysable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6d38dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def product_space(space: Dict[str, Iterable]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    space: {\"param\": [v1, v2, ...], \"param2\": [...]}\n",
    "    -> liste de dicts (toutes les combinaisons, mélangées)\n",
    "    \"\"\"\n",
    "    keys = list(space.keys())\n",
    "    vals = [list(space[k]) for k in keys]\n",
    "    out = []\n",
    "    for combo in itertools.product(*vals):\n",
    "        out.append({k: v for k, v in zip(keys, combo)})\n",
    "    random.shuffle(out)\n",
    "    return out\n",
    "\n",
    "def pick_top(results: List[Dict], k: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Classement pénalisé: d'abord pénalité prune, puis -accuracy, puis temps moyen.\n",
    "    results: sorties de eval_cfg(...)\n",
    "    \"\"\"\n",
    "    def key(r):\n",
    "        pen = (1.0 if r[\"pruned_time\"] else 0.0) + (0.5 if r[\"pruned_acc\"] else 0.0)\n",
    "        return (pen, -r[\"mean_acc\"], r[\"mean_time\"])\n",
    "    return sorted(results, key=key)[:k]\n",
    "\n",
    "def save_phase_csv(path: Path, results: List[Dict], param_keys: List[str]):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        header = param_keys + [\"mean_acc\",\"std_acc\",\"mean_time\",\"total_time\",\"n_tasks\",\"pruned_time\",\"pruned_acc\"]\n",
    "        w.writerow(header)\n",
    "        for r in results:\n",
    "            row = [r[\"config\"].get(k, None) for k in param_keys]\n",
    "            row += [r[\"mean_acc\"], r[\"std_acc\"], r[\"mean_time\"], r[\"total_time\"], r[\"n_tasks\"],\n",
    "                    r[\"pruned_time\"], r[\"pruned_acc\"]]\n",
    "            w.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3365f578",
   "metadata": {},
   "source": [
    "\n",
    "## **3) Évaluation d'une config avec pruning (multi-tâches)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8fce2d",
   "metadata": {},
   "source": [
    "Cette fonction évalue une configuration donnée sur plusieurs tasks successives,  \n",
    "en appliquant des **règles de pruning** (temps ou accuracy) pour interrompre les essais inutiles.\n",
    "\n",
    "Étapes :\n",
    "1. instanciation d’un agent via `make_agent(cfg)`,  \n",
    "2. entraînement et évaluation sur chaque task,  \n",
    "3. application des règles d’arrêt :\n",
    "   - **temps** : dépassement du budget (`time_factor_stop × time_budget_s`),  \n",
    "   - **accuracy** : performance insuffisante selon les seuils `A_first`, `A_mean`, etc.\n",
    "\n",
    "Sortie : un dictionnaire contenant les moyennes et écarts-types de performance,  \n",
    "les temps d’exécution, et les indicateurs de pruning :\n",
    "\n",
    "| Clé | Signification |\n",
    "|:----|:---------------|\n",
    "| `mean_acc` | moyenne des accuracies sur les tasks évaluées |\n",
    "| `std_acc` | écart-type des accuracies |\n",
    "| `mean_time` | temps moyen par task |\n",
    "| `pruned_time` | True si arrêt pour dépassement de temps |\n",
    "| `pruned_acc` | True si arrêt pour performance insuffisante |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0663d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cfg(cfg: Dict,\n",
    "             make_agent: Callable[[Dict], object],\n",
    "             env_tasks: int,\n",
    "             prune_rules: Dict,\n",
    "             seed: int = 42,\n",
    "             include_init_time: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    prune_rules attend:\n",
    "      {\n",
    "        \"time_budget_s\": 58.0,\n",
    "        \"time_factor_stop\": 1.20,     # stop si t_task > factor * budget\n",
    "        \"phase\": \"A\" / \"B\" / None,\n",
    "        \"A_first\": 0.970, \"A_mean\": 0.970,\n",
    "        \"B_first\": 0.980, \"B_mean\": 0.980\n",
    "      }\n",
    "    include_init_time:\n",
    "      - False: on mesure train+predict (comme avant)\n",
    "      - True : on mesure init+reset+train+predict (proche plateforme)\n",
    "    \"\"\"\n",
    "    env = PermutedMNISTEnv(number_episodes=env_tasks)\n",
    "    env.set_seed(seed)\n",
    "\n",
    "    accs, times = [], []\n",
    "    pruned_time = False\n",
    "    pruned_acc = False\n",
    "    phase = prune_rules.get(\"phase\", None)\n",
    "\n",
    "    t_id = 0\n",
    "    while True:\n",
    "        task = env.get_next_task()\n",
    "        if task is None:\n",
    "            break\n",
    "        t_id += 1\n",
    "\n",
    "        if include_init_time:\n",
    "            t0 = time.time()\n",
    "            agent = make_agent(cfg)     # on compte le coût d'instanciation\n",
    "            agent.reset()\n",
    "            t_start = t0\n",
    "        else:\n",
    "            agent = make_agent(cfg)\n",
    "            agent.reset()\n",
    "            t_start = time.time()\n",
    "\n",
    "        agent.train(task[\"X_train\"], task[\"y_train\"])\n",
    "        preds = agent.predict(task[\"X_test\"])\n",
    "        elapsed = time.time() - t_start\n",
    "\n",
    "        acc = env.evaluate(preds, task[\"y_test\"])\n",
    "        accs.append(acc)\n",
    "        times.append(elapsed)\n",
    "\n",
    "        # Pruning temps\n",
    "        if elapsed > prune_rules[\"time_factor_stop\"] * prune_rules[\"time_budget_s\"]:\n",
    "            pruned_time = True\n",
    "            break\n",
    "\n",
    "        # Pruning accuracy\n",
    "        if phase == \"A\":\n",
    "            if len(accs) == 1 and accs[0] < prune_rules[\"A_first\"]:\n",
    "                pruned_acc = True; break\n",
    "            if len(accs) >= 2 and np.mean(accs) < prune_rules[\"A_mean\"]:\n",
    "                pruned_acc = True; break\n",
    "        if phase == \"B\":\n",
    "            if len(accs) == 1 and accs[0] < prune_rules[\"B_first\"]:\n",
    "                pruned_acc = True; break\n",
    "            if len(accs) >= 2 and np.mean(accs) < prune_rules[\"B_mean\"]:\n",
    "                pruned_acc = True; break\n",
    "\n",
    "        if t_id >= env_tasks:\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"config\": cfg,\n",
    "        \"mean_acc\": float(np.mean(accs) if accs else 0.0),\n",
    "        \"std_acc\": float(np.std(accs) if accs else 0.0),\n",
    "        \"mean_time\": float(np.mean(times) if times else 0.0),\n",
    "        \"total_time\": float(np.sum(times)),\n",
    "        \"n_tasks\": len(accs),\n",
    "        \"pruned_time\": pruned_time,\n",
    "        \"pruned_acc\": pruned_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70625cad",
   "metadata": {},
   "source": [
    "\n",
    "## **4) Orchestration d'une phase (A / B / C)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4292de7f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Cette fonction exécute une phase complète de la recherche (A, B ou C).  \n",
    "Elle enchaîne plusieurs évaluations `eval_cfg` sur la liste de configurations à tester.\n",
    "\n",
    "**Fonctions principales :**\n",
    "- `pretty_cfg(cfg)` : formate une configuration sous forme lisible pour les logs.  \n",
    "- `run_phase(label, cfg_list, make_agent, env_tasks, prune_rules, out_csv, param_keys, include_init_time)` :\n",
    "  - lance la boucle d’évaluation des configurations,\n",
    "  - affiche un log clair (accuracy, temps, statut de pruning),\n",
    "  - sauvegarde les résultats dans un CSV si `out_csv` est défini.\n",
    "\n",
    "**Design “stateless” :** chaque phase est indépendante (A ne dépend pas directement de B),  \n",
    "ce qui simplifie le debugging et la réutilisation du pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cff6e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_cfg(cfg: dict, keys: list[str] | None = None) -> str:\n",
    "    if keys is None:\n",
    "        keys = sorted(cfg.keys())\n",
    "    items = []\n",
    "    for k in keys:\n",
    "        v = cfg.get(k, None)\n",
    "        if isinstance(v, (list, tuple)):\n",
    "            v = tuple(v)\n",
    "        items.append(f\"{k}={v}\")\n",
    "    return \"{ \" + \", \".join(items) + \" }\"\n",
    "\n",
    "def run_phase(label: str,\n",
    "              cfg_list: list[dict],\n",
    "              make_agent: Callable[[dict], object],\n",
    "              env_tasks: int,\n",
    "              prune_rules: dict,\n",
    "              out_csv: Path | None = None,\n",
    "              param_keys: list[str] | None = None,\n",
    "              include_init_time: bool = False) -> list[dict]:\n",
    "    print(f\"\\n=== Phase {label}: N={len(cfg_list)}, tasks={env_tasks}, phase={prune_rules.get('phase', None)} ===\")\n",
    "    results = []\n",
    "    for i, cfg in enumerate(cfg_list, 1):\n",
    "        r = eval_cfg(cfg,\n",
    "                     make_agent=make_agent,\n",
    "                     env_tasks=env_tasks,\n",
    "                     prune_rules=prune_rules,\n",
    "                     seed=SEED,\n",
    "                     include_init_time=include_init_time)\n",
    "        tag = \" PRUNE[T]\" if r[\"pruned_time\"] else (\" PRUNE[A]\" if r[\"pruned_acc\"] else \"\")\n",
    "        hp_str = pretty_cfg(cfg, param_keys or list(cfg.keys()))\n",
    "        print(f\"[{label} {i}/{len(cfg_list)}] {hp_str}  ->  \"\n",
    "              f\"acc={r['mean_acc']:.4f}±{r['std_acc']:.4f} | t={r['mean_time']:.1f}s | tasks={r['n_tasks']}{tag}\")\n",
    "        results.append(r)\n",
    "    if out_csv and param_keys:\n",
    "        save_phase_csv(out_csv, results, param_keys)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94efc7b1",
   "metadata": {},
   "source": [
    "## **5) Pipeline complet prêt à l'emploi (A -> B -> C)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb4369e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Cette fonction orchestre toute la recherche d’hyperparamètres selon la stratégie progressive :\n",
    "\n",
    "1. **Phase A — Exploration large**  \n",
    "   Explore un grand nombre de configurations, élimine rapidement les modèles trop lents ou inefficaces.  \n",
    "   → Résultats sauvegardés dans `phase_A.csv`.\n",
    "\n",
    "2. **Phase B — Raffinement**  \n",
    "   Relance uniquement les meilleures configs de A (top-k), avec des seuils de pruning plus stricts.  \n",
    "   → Résultats dans `phase_B.csv`.\n",
    "\n",
    "3. **Phase C — Validation finale**  \n",
    "   Évalue les meilleures configs issues de B sur plus de tâches, sans pruning.  \n",
    "   → Résultats dans `phase_C.csv`.\n",
    "\n",
    "Enfin, la fonction écrit un **résumé JSON final** contenant les modèles les plus performants (TOP-3 par défaut).\n",
    "\n",
    "**Paramètres clés :**\n",
    "- `experiment` : dictionnaire complet décrivant l’expérience (agent, espace, règles, etc.)\n",
    "- `include_init_time` : si True, inclut le coût d’instanciation de l’agent dans le temps total\n",
    "- `verbose_top3` : si True, affiche les 3 meilleures configurations finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d07f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hparam_search(experiment: Dict, include_init_time: bool = False, verbose_top3: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Lance A -> B -> C pour un espace de recherche donné.\n",
    "    Paramètres clés dans `experiment` :\n",
    "      - agent_spec: (\"module.path\", \"AgentClass\")\n",
    "      - fixed_kwargs: kwargs fixes pour l'agent (ex: {\"time_budget_s\": 55.0, \"output_dim\": 10, \"seed\": 42})\n",
    "      - search_space: dict param -> list de valeurs\n",
    "      - n_A, n_B_keep, n_C_keep: tailles par phase\n",
    "      - tasks: {\"A\": int, \"B\": int, \"C\": int}\n",
    "      - prune: dict de règles de pruning pour A/B/C\n",
    "      - outdir: Path où écrire les CSV/JSON\n",
    "      - seed: int\n",
    "    include_init_time: True pour compter init+reset+train+predict (proche plateforme).\n",
    "    \"\"\"\n",
    "    outdir = experiment[\"outdir\"]; outdir.mkdir(parents=True, exist_ok=True)\n",
    "    param_keys = list(experiment[\"search_space\"].keys())\n",
    "\n",
    "    make_agent = make_agent_factory(\n",
    "        agent_spec=experiment[\"agent_spec\"],\n",
    "        fixed_kwargs=experiment.get(\"fixed_kwargs\", {}),\n",
    "        seed=experiment.get(\"seed\", 42)\n",
    "    )\n",
    "\n",
    "    all_cfgs = product_space(experiment[\"search_space\"])\n",
    "\n",
    "    # Phase A\n",
    "    A_cfgs = all_cfgs[:experiment[\"n_A\"]]\n",
    "    A = run_phase(\"A\", A_cfgs, make_agent,\n",
    "                  env_tasks=experiment[\"tasks\"][\"A\"],\n",
    "                  prune_rules=experiment[\"prune\"][\"A\"],\n",
    "                  out_csv=outdir/\"phase_A.csv\", param_keys=param_keys,\n",
    "                  include_init_time=include_init_time)\n",
    "\n",
    "    # Phase B (top de A)\n",
    "    B_cfgs = [r[\"config\"] for r in pick_top(A, experiment[\"n_B_keep\"])]\n",
    "    B = run_phase(\"B\", B_cfgs, make_agent,\n",
    "                  env_tasks=experiment[\"tasks\"][\"B\"],\n",
    "                  prune_rules=experiment[\"prune\"][\"B\"],\n",
    "                  out_csv=outdir/\"phase_B.csv\", param_keys=param_keys,\n",
    "                  include_init_time=include_init_time)\n",
    "\n",
    "    # Phase C (top de B)\n",
    "    C_cfgs = [r[\"config\"] for r in pick_top(B, experiment[\"n_C_keep\"])]\n",
    "    C = run_phase(\"C\", C_cfgs, make_agent,\n",
    "                  env_tasks=experiment[\"tasks\"][\"C\"],\n",
    "                  prune_rules=experiment[\"prune\"][\"C\"],\n",
    "                  out_csv=outdir/\"phase_C.csv\", param_keys=param_keys,\n",
    "                  include_init_time=include_init_time)\n",
    "\n",
    "    final = sorted(C, key=lambda r: (-r[\"mean_acc\"], r[\"mean_time\"]))\n",
    "    with open(outdir/\"final_top.json\", \"w\") as f:\n",
    "        json.dump(final[:3], f, indent=2)\n",
    "\n",
    "    if verbose_top3:\n",
    "        def _cfg_slice(r):\n",
    "            return {k: r['config'].get(k) for k in param_keys}\n",
    "        print(\"\\nTOP-3:\", [\n",
    "            (_cfg_slice(final[0]), final[0][\"mean_acc\"], final[0][\"mean_time\"]) if len(final)>0 else None,\n",
    "            (_cfg_slice(final[1]), final[1][\"mean_acc\"], final[1][\"mean_time\"]) if len(final)>1 else None,\n",
    "            (_cfg_slice(final[2]), final[2][\"mean_acc\"], final[2][\"mean_time\"]) if len(final)>2 else None,\n",
    "        ])\n",
    "\n",
    "    return {\"A\": A, \"B\": B, \"C\": C, \"final\": final}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cbf31d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Ces fonctions facilitent la construction d’espaces d’hyperparamètres cohérents et rapides à explorer.\n",
    "\n",
    "- **`hidden_from_lists`** : génère automatiquement des architectures cachées décroissantes (H1 ≥ H2 ≥ H3).  \n",
    "  Exemple : `[[1024, 512], [768, 384, 192]]`\n",
    "- **`grid_MLP`** : assemble un espace de recherche complet pour MLP, incluant :\n",
    "  - le nombre de couches cachées,\n",
    "  - le dropout,\n",
    "  - la taille de batch,\n",
    "  - le learning rate,\n",
    "  - le label smoothing,\n",
    "  - le poids de régularisation.\n",
    "\n",
    "Ces fonctions garantissent des combinaisons valides et homogènes pour la recherche.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b286ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====  A) Builders d'espaces de recherche (génériques) ====\n",
    "\n",
    "def hidden_from_lists(layer_value_lists: list[list[int]],\n",
    "                      enforce_nonincreasing: bool = True) -> list[tuple[int, ...]]:\n",
    "    \"\"\"\n",
    "    Exemple: [[1024, 1536], [512, 768]] -> [(1024,512), (1024,768), (1536,512), (1536,768)]\n",
    "    Si enforce_nonincreasing=True, garde seulement h1>=h2>=... (utile pour 2L/3L).\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    combos = list(itertools.product(*layer_value_lists))\n",
    "    if enforce_nonincreasing:\n",
    "        combos = [c for c in combos if all(c[i] >= c[i+1] for i in range(len(c)-1))]\n",
    "    return [tuple(c) for c in combos]\n",
    "\n",
    "def grid_MLP(hidden_tuples: list[tuple[int, ...]],\n",
    "             dropout: list[float],\n",
    "             batch_size: list[int],\n",
    "             learning_rate: list[float],\n",
    "             label_smoothing: list[float] = (0.0, 0.05),\n",
    "             max_epochs: list[int] = (10,),\n",
    "             val_fraction: list[float] = (0.10,),\n",
    "             weight_decay: list[float] = (1e-4,)) -> dict:\n",
    "    \"\"\"Construit le dict `search_space` attendu par run_hparam_search.\"\"\"\n",
    "    return {\n",
    "        \"hidden\": hidden_tuples,\n",
    "        \"dropout\": list(dropout),\n",
    "        \"batch_size\": list(batch_size),\n",
    "        \"learning_rate\": list(learning_rate),\n",
    "        \"label_smoothing\": list(label_smoothing),\n",
    "        \"max_epochs\": list(max_epochs),\n",
    "        \"val_fraction\": list(val_fraction),\n",
    "        \"weight_decay\": list(weight_decay),\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e7df9",
   "metadata": {},
   "source": [
    "Ces fonctions définissent les paramètres par défaut pour la recherche multi-phases :\n",
    "\n",
    "- **`preset_tasks(mode)`** : définit le nombre de configurations et de tâches par phase selon le mode choisi :  \n",
    "  - `\"sanity\"` → test rapide pour debug,  \n",
    "  - `\"quick\"` → configuration standard,  \n",
    "  - `\"full\"` → exploration exhaustive.  \n",
    "\n",
    "- **`preset_pruning(depth, strictness)`** : fixe les seuils d’arrêt anticipé selon :\n",
    "  - la **profondeur du réseau** (1, 2 ou 3 couches),\n",
    "  - et la **rigueur du pruning** (`loose`, `std`, `tight`).\n",
    "\n",
    "Ces presets permettent d’adapter automatiquement la stratégie à la complexité de l’architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====  B) Presets souples pour tasks + pruning ====\n",
    "\n",
    "def preset_tasks(mode: str = \"quick\") -> dict:\n",
    "    \"\"\"\n",
    "    Taille d’échantillonnage par phase.\n",
    "    \"\"\"\n",
    "    if mode == \"sanity\":\n",
    "        return {\"n_A\": 6, \"n_B_keep\": 3, \"n_C_keep\": 2,\n",
    "                \"tasks\": {\"A\": 3, \"B\": 6, \"C\": 10}}\n",
    "    elif mode == \"quick\":\n",
    "        return {\"n_A\": 30, \"n_B_keep\": 8, \"n_C_keep\": 3,\n",
    "                \"tasks\": {\"A\": 3, \"B\": 6, \"C\": 10}}\n",
    "    elif mode == \"full\":\n",
    "        return {\"n_A\": 60, \"n_B_keep\": 10, \"n_C_keep\": 5,\n",
    "                \"tasks\": {\"A\": 3, \"B\": 6, \"C\": 10}}\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'sanity' | 'quick' | 'full'\")\n",
    "\n",
    "def preset_pruning(depth: int, strictness: str = \"std\") -> dict:\n",
    "    \"\"\"\n",
    "    depth ∈ {1,2,3}; strictness ∈ {'loose','std','tight'} (seuils d'accuracy et time).\n",
    "    \"\"\"\n",
    "    tf = {\"loose\": 1.25, \"std\": 1.20 if depth==1 else (1.15 if depth==2 else 1.10), \"tight\": 1.10}\n",
    "    A_first = {1: 0.960, 2: 0.962, 3: 0.963}[depth]\n",
    "    A_mean  = {1: 0.965, 2: 0.968, 3: 0.969}[depth]\n",
    "    B_first = {1: 0.975, 2: 0.977, 3: 0.978}[depth]\n",
    "    B_mean  = {1: 0.978, 2: 0.980, 3: 0.981}[depth]\n",
    "    return {\n",
    "        \"A\": {\"time_budget_s\": 58.0, \"time_factor_stop\": tf[strictness], \"phase\": \"A\",\n",
    "              \"A_first\": A_first, \"A_mean\": A_mean},\n",
    "        \"B\": {\"time_budget_s\": 58.0, \"time_factor_stop\": tf[strictness], \"phase\": \"B\",\n",
    "              \"B_first\": B_first, \"B_mean\": B_mean},\n",
    "        \"C\": {\"time_budget_s\": 58.0, \"time_factor_stop\": tf[strictness], \"phase\": None}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a30dc",
   "metadata": {},
   "source": [
    "\n",
    "**Objectif :** assembler tous les composants d’une expérience complète dans un seul objet Python,\n",
    "directement exploitable par `run_hparam_search`.\n",
    "\n",
    "Cette fonction prend :\n",
    "- les spécifications d’agent (`agent_spec`),\n",
    "- l’espace de recherche (`search_space`),\n",
    "- la configuration des phases (`tasks_cfg`),\n",
    "- les règles de pruning (`prune_rules`),\n",
    "- et d’éventuels paramètres fixes (`fixed_kwargs`).\n",
    "\n",
    "Elle renvoie un dictionnaire normalisé contenant toutes les informations nécessaires à la recherche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3260689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====  C) Fabricant d'expérience générique ====\n",
    "\n",
    "def make_experiment(agent_spec: tuple[str,str],\n",
    "                    search_space: dict,\n",
    "                    outdir: Path,\n",
    "                    tasks_cfg: dict,\n",
    "                    prune_rules: dict,\n",
    "                    fixed_kwargs: dict | None = None,\n",
    "                    seed: int = 42) -> dict:\n",
    "    \"\"\"\n",
    "    Assemble l'objet `experiment` attendu par run_hparam_search.\n",
    "    \"\"\"\n",
    "    if fixed_kwargs is None:\n",
    "        fixed_kwargs = {}\n",
    "    fixed_defaults = {\"time_budget_s\": 55.0, \"output_dim\": 10, \"seed\": seed}\n",
    "    fixed_defaults.update(fixed_kwargs)\n",
    "\n",
    "    return {\n",
    "        \"agent_spec\": agent_spec,\n",
    "        \"fixed_kwargs\": fixed_defaults,\n",
    "        \"search_space\": search_space,\n",
    "        \"n_A\": tasks_cfg[\"n_A\"], \"n_B_keep\": tasks_cfg[\"n_B_keep\"], \"n_C_keep\": tasks_cfg[\"n_C_keep\"],\n",
    "        \"tasks\": tasks_cfg[\"tasks\"],\n",
    "        \"prune\": prune_rules,\n",
    "        \"outdir\": outdir,\n",
    "        \"seed\": seed\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df91f4b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Cette fonction est une **interface simplifiée** pour lancer rapidement une expérience complète.\n",
    "\n",
    "- Appelle `run_hparam_search` avec les bons paramètres,\n",
    "- Sauvegarde automatiquement les résultats au format `.json`,\n",
    "- Et affiche un **TOP-k** des meilleures configurations (par défaut TOP-3).\n",
    "\n",
    "**Usage typique :**\n",
    "```python\n",
    "res = run_and_report(\"Demo\", experiment=exp, topk=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc84aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====  D) Runner compact (rapport + JSON) ====\n",
    "\n",
    "def run_and_report(tag: str, experiment: dict, include_init_time: bool = True, topk: int = 3):\n",
    "    res = run_hparam_search(experiment, include_init_time=include_init_time, verbose_top3=False)\n",
    "    final = res[\"final\"]\n",
    "    if not final:\n",
    "        print(f\"\\n[{tag}] Aucun modèle final (pruning partout ?)\")\n",
    "        return res\n",
    "    print(f\"\\n[{tag}] TOP-{topk} (tri = acc desc, puis temps asc)\")\n",
    "    for i, r in enumerate(sorted(final, key=lambda x: (-x[\"mean_acc\"], x[\"mean_time\"]))[:topk], 1):\n",
    "        print(f\"#{i} cfg={r['config']} | acc={r['mean_acc']:.4f} | t={r['mean_time']:.1f}s\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c7e67f",
   "metadata": {},
   "source": [
    "# **Recherches d'hyperparamètres**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e784794",
   "metadata": {},
   "source": [
    "## **Mode d’emploi — Lancer une expérience de recherche d’hyperparamètres**\n",
    "\n",
    "Cette section montre comment exécuter une recherche complète d’hyperparamètres en utilisant le pipeline modulaire défini précédemment.\n",
    "\n",
    "L’approche repose sur une logique en cinq étapes simples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Étape 1 - Déclarer l’agent à tester**\n",
    "Spécifie :\n",
    "- le module et la classe de l’agent à utiliser (`AGENT_SPEC`),\n",
    "- les paramètres fixes communs à toutes les expériences (`FIXED_KW`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Étape 2 - Définir l’espace de recherche**\n",
    "Construit la grille d’hyperparamètres à explorer :\n",
    "- architecture cachée (hidden layers),\n",
    "- dropout, batch size, learning rate, label smoothing, etc.  \n",
    "Utilise les fonctions **`hidden_from_lists`** et **`grid_MLP`** pour créer un espace cohérent.\n",
    "\n",
    "---\n",
    "\n",
    "### **Étape 3 - Configurer la taille des phases et les règles de pruning**\n",
    "Adapte la complexité de l’expérience à ton objectif :\n",
    "- Mode *sanity* : test rapide de validation,\n",
    "- Mode *quick* : recherche standard,\n",
    "- Mode *full* : exploration exhaustive.  \n",
    "\n",
    "Ajuste également la profondeur du réseau et la rigueur du pruning selon :\n",
    "- `depth` : nombre de couches cachées (1, 2, 3, ...),\n",
    "- `strictness` : niveau de rigueur (`loose`, `std`, `tight`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Étape 4 - Construire l’expérience complète**\n",
    "Assemble tous les composants dans un objet **`experiment`** prêt à être utilisé avec :\n",
    "- l’agent (`AGENT_SPEC`),\n",
    "- l’espace de recherche (`search_space`),\n",
    "- les règles de pruning (`prune_rules`),\n",
    "- les tailles de phases (`tasks_cfg`),\n",
    "- et le répertoire de sortie (`outdir`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Étape 5 - Lancer la recherche et afficher les résultats**\n",
    "Exécute automatiquement la séquence **A → B → C**, en sauvegardant les résultats CSV et le résumé JSON final.  \n",
    "Le pipeline renvoie :\n",
    "- la moyenne et l’écart-type des accuracies (`mean_acc`, `std_acc`),\n",
    "- le temps moyen d’exécution par tâche (`mean_time`),\n",
    "- les indicateurs de pruning (`pruned_time`, `pruned_acc`),\n",
    "- et les fichiers produits : `phase_A.csv`, `phase_B.csv`, `phase_C.csv`, `final_top.json`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Astuce**\n",
    "Pour tester différentes profondeurs de MLP :\n",
    "- modifie `depth` dans `preset_pruning()`,\n",
    "- change la liste `hidden_tuples`,\n",
    "- ajuste le dossier de sortie `outdir`.\n",
    "\n",
    "Chaque expérience est totalement indépendante et reproductible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6c588",
   "metadata": {},
   "source": [
    "## **MLP à 1 couche**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdda42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Phase A: N=30, tasks=3, phase=A ===\n",
      "[A 1/30] { hidden=(1024,), dropout=0.05, batch_size=3072, learning_rate=0.001, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9625±0.0006 | t=8.5s | tasks=2 PRUNE[A]\n",
      "[A 2/30] { hidden=(512,), dropout=0.1, batch_size=3072, learning_rate=0.001, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9544±0.0000 | t=4.8s | tasks=1 PRUNE[A]\n",
      "[A 3/30] { hidden=(768,), dropout=0.0, batch_size=3072, learning_rate=0.001, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9585±0.0000 | t=3.9s | tasks=1 PRUNE[A]\n",
      "[A 4/30] { hidden=(2048,), dropout=0.0, batch_size=2048, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9814±0.0007 | t=10.4s | tasks=3\n",
      "[A 5/30] { hidden=(1536,), dropout=0.05, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9826±0.0004 | t=13.8s | tasks=3\n",
      "[A 6/30] { hidden=(768,), dropout=0.0, batch_size=2048, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9729±0.0003 | t=4.5s | tasks=3\n",
      "[A 7/30] { hidden=(1024,), dropout=0.0, batch_size=3072, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9672±0.0007 | t=5.8s | tasks=3\n",
      "[A 8/30] { hidden=(1536,), dropout=0.1, batch_size=1024, learning_rate=0.0012, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9785±0.0004 | t=13.0s | tasks=3\n",
      "[A 9/30] { hidden=(512,), dropout=0.0, batch_size=2048, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9721±0.0005 | t=4.0s | tasks=3\n",
      "[A 10/30] { hidden=(768,), dropout=0.1, batch_size=3072, learning_rate=0.0012, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9625±0.0005 | t=6.3s | tasks=2 PRUNE[A]\n",
      "[A 11/30] { hidden=(1536,), dropout=0.1, batch_size=3072, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9729±0.0004 | t=11.0s | tasks=3\n",
      "[A 12/30] { hidden=(1024,), dropout=0.1, batch_size=3072, learning_rate=0.001, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9621±0.0003 | t=7.7s | tasks=2 PRUNE[A]\n",
      "[A 13/30] { hidden=(512,), dropout=0.0, batch_size=1024, learning_rate=0.0015, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9801±0.0000 | t=3.2s | tasks=3\n",
      "[A 14/30] { hidden=(2048,), dropout=0.05, batch_size=3072, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9767±0.0006 | t=17.7s | tasks=3\n",
      "[A 15/30] { hidden=(2048,), dropout=0.0, batch_size=3072, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9741±0.0006 | t=10.0s | tasks=3\n",
      "[A 16/30] { hidden=(1024,), dropout=0.1, batch_size=2048, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9758±0.0003 | t=9.1s | tasks=3\n",
      "[A 17/30] { hidden=(2048,), dropout=0.0, batch_size=2048, learning_rate=0.0015, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9776±0.0002 | t=11.2s | tasks=3\n",
      "[A 18/30] { hidden=(768,), dropout=0.1, batch_size=1024, learning_rate=0.0015, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9815±0.0002 | t=7.4s | tasks=3\n",
      "[A 19/30] { hidden=(1536,), dropout=0.1, batch_size=3072, learning_rate=0.0012, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9688±0.0007 | t=12.2s | tasks=3\n",
      "[A 20/30] { hidden=(1024,), dropout=0.0, batch_size=3072, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9709±0.0004 | t=6.1s | tasks=3\n",
      "[A 21/30] { hidden=(2048,), dropout=0.05, batch_size=3072, learning_rate=0.0012, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9716±0.0007 | t=19.1s | tasks=3\n",
      "[A 22/30] { hidden=(1536,), dropout=0.1, batch_size=1024, learning_rate=0.0015, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9845±0.0008 | t=13.9s | tasks=3\n",
      "[A 23/30] { hidden=(768,), dropout=0.1, batch_size=2048, learning_rate=0.0015, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9727±0.0009 | t=7.1s | tasks=3\n",
      "[A 24/30] { hidden=(2048,), dropout=0.1, batch_size=3072, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9760±0.0010 | t=17.8s | tasks=3\n",
      "[A 25/30] { hidden=(1536,), dropout=0.1, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9823±0.0006 | t=14.0s | tasks=3\n",
      "[A 26/30] { hidden=(2048,), dropout=0.1, batch_size=2048, learning_rate=0.0015, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9777±0.0001 | t=18.9s | tasks=3\n",
      "[A 27/30] { hidden=(512,), dropout=0.0, batch_size=2048, learning_rate=0.001, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9627±0.0001 | t=4.1s | tasks=2 PRUNE[A]\n",
      "[A 28/30] { hidden=(1024,), dropout=0.0, batch_size=3072, learning_rate=0.0012, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9646±0.0010 | t=6.8s | tasks=2 PRUNE[A]\n",
      "[A 29/30] { hidden=(768,), dropout=0.1, batch_size=3072, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9656±0.0003 | t=6.8s | tasks=3\n",
      "[A 30/30] { hidden=(2048,), dropout=0.1, batch_size=2048, learning_rate=0.0015, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9821±0.0008 | t=16.7s | tasks=3\n",
      "\n",
      "=== Phase B: N=8, tasks=6, phase=B ===\n",
      "[B 1/8] { hidden=(1536,), dropout=0.1, batch_size=1024, learning_rate=0.0015, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9842±0.0008 | t=14.0s | tasks=6\n",
      "[B 2/8] { hidden=(1536,), dropout=0.05, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9824±0.0005 | t=14.0s | tasks=6\n",
      "[B 3/8] { hidden=(1536,), dropout=0.1, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9823±0.0005 | t=14.1s | tasks=6\n",
      "[B 4/8] { hidden=(2048,), dropout=0.1, batch_size=2048, learning_rate=0.0015, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9823±0.0009 | t=18.4s | tasks=6\n",
      "[B 5/8] { hidden=(768,), dropout=0.1, batch_size=1024, learning_rate=0.0015, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9815±0.0001 | t=8.0s | tasks=6\n",
      "[B 6/8] { hidden=(2048,), dropout=0.0, batch_size=2048, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9808±0.0011 | t=11.1s | tasks=6\n",
      "[B 7/8] { hidden=(512,), dropout=0.0, batch_size=1024, learning_rate=0.0015, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9801±0.0003 | t=3.6s | tasks=6\n",
      "[B 8/8] { hidden=(1536,), dropout=0.1, batch_size=1024, learning_rate=0.0012, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9787±0.0003 | t=14.2s | tasks=6\n",
      "\n",
      "=== Phase C: N=3, tasks=10, phase=None ===\n",
      "[C 1/3] { hidden=(1536,), dropout=0.1, batch_size=1024, learning_rate=0.0015, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9842±0.0007 | t=15.4s | tasks=10\n",
      "[C 2/3] { hidden=(1536,), dropout=0.05, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9825±0.0005 | t=15.9s | tasks=10\n",
      "[C 3/3] { hidden=(2048,), dropout=0.1, batch_size=2048, learning_rate=0.0015, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9822±0.0008 | t=20.4s | tasks=10\n",
      "\n",
      "[1-LAYER quick] TOP-3 (tri = acc desc, puis temps asc)\n",
      "#1 cfg={'hidden': (1536,), 'dropout': 0.1, 'batch_size': 1024, 'learning_rate': 0.0015, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001} | acc=0.9842 | t=15.4s\n",
      "#2 cfg={'hidden': (1536,), 'dropout': 0.05, 'batch_size': 1024, 'learning_rate': 0.001, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001} | acc=0.9825 | t=15.9s\n",
      "#3 cfg={'hidden': (2048,), 'dropout': 0.1, 'batch_size': 2048, 'learning_rate': 0.0015, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001} | acc=0.9822 | t=20.4s\n"
     ]
    }
   ],
   "source": [
    "AGENT_SPEC = (\"models.MLP.agent_mlp_v3\", \"Agent\")\n",
    "OUTDIR = Path(\"./experiments/exp_1L\")\n",
    "\n",
    "hidden = hidden_from_lists([[512, 768, 1024, 1536, 2048]], enforce_nonincreasing=False)\n",
    "space  = grid_MLP(\n",
    "    hidden_tuples=hidden,\n",
    "    dropout=[0.00, 0.05, 0.10],\n",
    "    batch_size=[1024, 2048, 3072],\n",
    "    learning_rate=[1e-3, 1.2e-3, 1.5e-3],\n",
    "    label_smoothing=[0.0, 0.05]\n",
    ")\n",
    "\n",
    "tasks  = preset_tasks(\"quick\")\n",
    "prune  = preset_pruning(depth=1, strictness=\"std\")\n",
    "\n",
    "exp = make_experiment(AGENT_SPEC, space, OUTDIR, tasks, prune)\n",
    "res_1L = run_and_report(\"1-LAYER quick\", exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda49ab1",
   "metadata": {},
   "source": [
    "## **MLP à 2 couches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b8ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Phase A: N=30, tasks=3, phase=A ===\n",
      "[A 1/30] { hidden=(1536, 384), dropout=0.05, batch_size=3072, learning_rate=0.0009, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9722±0.0013 | t=15.1s | tasks=3\n",
      "[A 2/30] { hidden=(768, 256), dropout=0.1, batch_size=1024, learning_rate=0.0009, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9796±0.0009 | t=8.3s | tasks=3\n",
      "[A 3/30] { hidden=(1024, 512), dropout=0.0, batch_size=2048, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9815±0.0002 | t=9.5s | tasks=3\n",
      "[A 4/30] { hidden=(1536, 384), dropout=0.0, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9850±0.0004 | t=11.2s | tasks=3\n",
      "[A 5/30] { hidden=(1280, 384), dropout=0.1, batch_size=3072, learning_rate=0.0009, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9711±0.0004 | t=12.7s | tasks=3\n",
      "[A 6/30] { hidden=(1280, 256), dropout=0.05, batch_size=3072, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9740±0.0001 | t=11.5s | tasks=3\n",
      "[A 7/30] { hidden=(768, 256), dropout=0.05, batch_size=2048, learning_rate=0.0009, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9723±0.0006 | t=8.3s | tasks=3\n",
      "[A 8/30] { hidden=(1280, 384), dropout=0.0, batch_size=3072, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9759±0.0009 | t=8.1s | tasks=3\n",
      "[A 9/30] { hidden=(768, 384), dropout=0.1, batch_size=1024, learning_rate=0.001, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9788±0.0002 | t=9.1s | tasks=3\n",
      "[A 10/30] { hidden=(1024, 256), dropout=0.1, batch_size=1024, learning_rate=0.0012, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9803±0.0009 | t=11.3s | tasks=3\n",
      "[A 11/30] { hidden=(768, 256), dropout=0.1, batch_size=2048, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9779±0.0003 | t=8.4s | tasks=3\n",
      "[A 12/30] { hidden=(1280, 384), dropout=0.1, batch_size=2048, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9816±0.0003 | t=13.2s | tasks=3\n",
      "[A 13/30] { hidden=(1536, 256), dropout=0.1, batch_size=2048, learning_rate=0.0012, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9770±0.0007 | t=13.9s | tasks=3\n",
      "[A 14/30] { hidden=(1536, 256), dropout=0.05, batch_size=3072, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9767±0.0002 | t=13.4s | tasks=3\n",
      "[A 15/30] { hidden=(1280, 384), dropout=0.0, batch_size=2048, learning_rate=0.0012, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9774±0.0007 | t=8.7s | tasks=3\n",
      "[A 16/30] { hidden=(1280, 256), dropout=0.1, batch_size=3072, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9780±0.0006 | t=11.5s | tasks=3\n",
      "[A 17/30] { hidden=(768, 512), dropout=0.05, batch_size=3072, learning_rate=0.001, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9689±0.0009 | t=9.9s | tasks=3\n",
      "[A 18/30] { hidden=(768, 512), dropout=0.05, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9838±0.0011 | t=10.4s | tasks=3\n",
      "[A 19/30] { hidden=(1024, 768), dropout=0.05, batch_size=2048, learning_rate=0.0012, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9794±0.0009 | t=15.7s | tasks=3\n",
      "[A 20/30] { hidden=(1024, 384), dropout=0.05, batch_size=1024, learning_rate=0.001, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9793±0.0012 | t=11.7s | tasks=3\n",
      "[A 21/30] { hidden=(1280, 512), dropout=0.1, batch_size=1024, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9859±0.0004 | t=15.6s | tasks=3\n",
      "[A 22/30] { hidden=(1280, 256), dropout=0.0, batch_size=2048, learning_rate=0.0012, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9772±0.0009 | t=7.9s | tasks=3\n",
      "[A 23/30] { hidden=(1024, 768), dropout=0.05, batch_size=3072, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9777±0.0002 | t=14.1s | tasks=3\n",
      "[A 24/30] { hidden=(768, 256), dropout=0.1, batch_size=3072, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9716±0.0009 | t=8.0s | tasks=3\n",
      "[A 25/30] { hidden=(1024, 512), dropout=0.1, batch_size=3072, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9769±0.0006 | t=12.4s | tasks=3\n",
      "[A 26/30] { hidden=(1280, 384), dropout=0.0, batch_size=2048, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9800±0.0009 | t=8.7s | tasks=3\n",
      "[A 27/30] { hidden=(1024, 256), dropout=0.05, batch_size=2048, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9777±0.0002 | t=10.9s | tasks=3\n",
      "[A 28/30] { hidden=(768, 512), dropout=0.0, batch_size=1024, learning_rate=0.001, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9780±0.0005 | t=6.9s | tasks=3\n",
      "[A 29/30] { hidden=(1536, 384), dropout=0.1, batch_size=3072, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9798±0.0007 | t=15.0s | tasks=3\n",
      "[A 30/30] { hidden=(1536, 256), dropout=0.05, batch_size=1024, learning_rate=0.0009, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9792±0.0003 | t=14.8s | tasks=3\n",
      "\n",
      "=== Phase B: N=8, tasks=6, phase=B ===\n",
      "[B 1/8] { hidden=(1280, 512), dropout=0.1, batch_size=1024, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9861±0.0003 | t=15.4s | tasks=6\n",
      "[B 2/8] { hidden=(1536, 384), dropout=0.0, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9853±0.0004 | t=11.2s | tasks=6\n",
      "[B 3/8] { hidden=(768, 512), dropout=0.05, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9836±0.0008 | t=10.7s | tasks=6\n",
      "[B 4/8] { hidden=(1280, 384), dropout=0.1, batch_size=2048, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9821±0.0007 | t=13.2s | tasks=6\n",
      "[B 5/8] { hidden=(1024, 512), dropout=0.0, batch_size=2048, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9806±0.0010 | t=9.3s | tasks=6\n",
      "[B 6/8] { hidden=(1024, 256), dropout=0.1, batch_size=1024, learning_rate=0.0012, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9797±0.0005 | t=10.7s | tasks=2 PRUNE[A]\n",
      "[B 7/8] { hidden=(1280, 384), dropout=0.0, batch_size=2048, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9798±0.0010 | t=8.7s | tasks=2 PRUNE[A]\n",
      "[B 8/8] { hidden=(1536, 384), dropout=0.1, batch_size=3072, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9798±0.0007 | t=14.9s | tasks=3 PRUNE[A]\n",
      "\n",
      "=== Phase C: N=3, tasks=10, phase=None ===\n",
      "[C 1/3] { hidden=(1280, 512), dropout=0.1, batch_size=1024, learning_rate=0.0012, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9857±0.0008 | t=15.5s | tasks=10\n",
      "[C 2/3] { hidden=(1536, 384), dropout=0.0, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9854±0.0006 | t=11.4s | tasks=10\n",
      "[C 3/3] { hidden=(768, 512), dropout=0.05, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9838±0.0010 | t=11.5s | tasks=10\n",
      "\n",
      "[2-LAYER quick] TOP-3 (tri = acc desc, puis temps asc)\n",
      "#1 cfg={'hidden': (1280, 512), 'dropout': 0.1, 'batch_size': 1024, 'learning_rate': 0.0012, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001} | acc=0.9857 | t=15.5s\n",
      "#2 cfg={'hidden': (1536, 384), 'dropout': 0.0, 'batch_size': 1024, 'learning_rate': 0.001, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001} | acc=0.9854 | t=11.4s\n",
      "#3 cfg={'hidden': (768, 512), 'dropout': 0.05, 'batch_size': 1024, 'learning_rate': 0.001, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001} | acc=0.9838 | t=11.5s\n"
     ]
    }
   ],
   "source": [
    "AGENT_SPEC = (\"models.MLP.agent_mlp_v3\", \"Agent\")\n",
    "OUTDIR = Path(\"./experiments/exp_2L\")\n",
    "\n",
    "hidden = hidden_from_lists(\n",
    "    [[768, 1024, 1280, 1536],   # H1\n",
    "     [256, 384, 512, 768]],     # H2\n",
    "    enforce_nonincreasing=True\n",
    ")\n",
    "space = grid_MLP(\n",
    "    hidden_tuples=hidden,\n",
    "    dropout=[0.00, 0.05, 0.10],\n",
    "    batch_size=[1024, 2048, 3072],\n",
    "    learning_rate=[9e-4, 1.0e-3, 1.2e-3],\n",
    "    label_smoothing=[0.0, 0.05]\n",
    ")\n",
    "\n",
    "tasks = preset_tasks(\"quick\")\n",
    "prune = preset_pruning(depth=2, strictness=\"std\")\n",
    "\n",
    "exp = make_experiment(AGENT_SPEC, space, OUTDIR, tasks, prune)\n",
    "res_2L = run_and_report(\"2-LAYER quick\", exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe865c0",
   "metadata": {},
   "source": [
    "## **MLP à 3 couches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b2644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Phase A: N=30, tasks=3, phase=A ===\n",
      "[A 1/30] { hidden=(1024, 384, 320), dropout=0.05, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9837±0.0013 | t=15.2s | tasks=3\n",
      "[A 2/30] { hidden=(1024, 640, 320), dropout=0.1, batch_size=2048, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9817±0.0001 | t=17.4s | tasks=3\n",
      "[A 3/30] { hidden=(1280, 640, 320), dropout=0.1, batch_size=1024, learning_rate=0.0009, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9804±0.0013 | t=20.0s | tasks=3\n",
      "[A 4/30] { hidden=(1024, 640, 256), dropout=0.1, batch_size=1024, learning_rate=0.0009, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9803±0.0005 | t=16.0s | tasks=3\n",
      "[A 5/30] { hidden=(1280, 640, 256), dropout=0.05, batch_size=1024, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9851±0.0009 | t=18.4s | tasks=3\n",
      "[A 6/30] { hidden=(1280, 384, 320), dropout=0.05, batch_size=3072, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9780±0.0004 | t=16.5s | tasks=3\n",
      "[A 7/30] { hidden=(896, 384, 192), dropout=0.05, batch_size=1024, learning_rate=0.0008, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9784±0.0006 | t=12.3s | tasks=3\n",
      "[A 8/30] { hidden=(896, 640, 192), dropout=0.05, batch_size=3072, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9756±0.0003 | t=15.0s | tasks=3\n",
      "[A 9/30] { hidden=(1280, 512, 192), dropout=0.05, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9844±0.0005 | t=16.6s | tasks=3\n",
      "[A 10/30] { hidden=(896, 512, 256), dropout=0.05, batch_size=3072, learning_rate=0.0008, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9674±0.0001 | t=13.0s | tasks=2 PRUNE[A]\n",
      "[A 11/30] { hidden=(896, 640, 192), dropout=0.05, batch_size=2048, learning_rate=0.0008, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9790±0.0009 | t=15.2s | tasks=3\n",
      "[A 12/30] { hidden=(896, 384, 256), dropout=0.1, batch_size=3072, learning_rate=0.0009, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9701±0.0006 | t=11.7s | tasks=3\n",
      "[A 13/30] { hidden=(896, 512, 192), dropout=0.1, batch_size=3072, learning_rate=0.0008, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9676±0.0018 | t=13.5s | tasks=2 PRUNE[A]\n",
      "[A 14/30] { hidden=(1280, 512, 320), dropout=0.1, batch_size=1024, learning_rate=0.0008, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9844±0.0006 | t=19.1s | tasks=3\n",
      "[A 15/30] { hidden=(1280, 512, 192), dropout=0.1, batch_size=3072, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9779±0.0005 | t=15.6s | tasks=3\n",
      "[A 16/30] { hidden=(1024, 384, 192), dropout=0.1, batch_size=3072, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9764±0.0004 | t=13.6s | tasks=3\n",
      "[A 17/30] { hidden=(1280, 384, 192), dropout=0.1, batch_size=1024, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9849±0.0000 | t=17.5s | tasks=3\n",
      "[A 18/30] { hidden=(896, 384, 320), dropout=0.05, batch_size=2048, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9798±0.0005 | t=14.4s | tasks=3\n",
      "[A 19/30] { hidden=(1024, 512, 320), dropout=0.1, batch_size=2048, learning_rate=0.0008, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9799±0.0007 | t=17.4s | tasks=3\n",
      "[A 20/30] { hidden=(1280, 640, 320), dropout=0.1, batch_size=2048, learning_rate=0.0009, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9783±0.0008 | t=18.9s | tasks=3\n",
      "[A 21/30] { hidden=(1024, 512, 320), dropout=0.1, batch_size=1024, learning_rate=0.0009, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9803±0.0004 | t=17.4s | tasks=3\n",
      "[A 22/30] { hidden=(1024, 640, 192), dropout=0.05, batch_size=2048, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9810±0.0011 | t=16.6s | tasks=3\n",
      "[A 23/30] { hidden=(896, 512, 256), dropout=0.1, batch_size=3072, learning_rate=0.001, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9721±0.0006 | t=12.4s | tasks=3\n",
      "[A 24/30] { hidden=(1280, 640, 256), dropout=0.1, batch_size=2048, learning_rate=0.0009, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9770±0.0010 | t=19.0s | tasks=3\n",
      "[A 25/30] { hidden=(1280, 512, 192), dropout=0.1, batch_size=3072, learning_rate=0.0008, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9754±0.0004 | t=19.1s | tasks=3\n",
      "[A 26/30] { hidden=(1024, 640, 192), dropout=0.1, batch_size=3072, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9769±0.0003 | t=15.7s | tasks=3\n",
      "[A 27/30] { hidden=(1024, 384, 320), dropout=0.05, batch_size=3072, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9768±0.0001 | t=13.0s | tasks=3\n",
      "[A 28/30] { hidden=(1024, 512, 320), dropout=0.1, batch_size=1024, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9837±0.0000 | t=15.4s | tasks=3\n",
      "[A 29/30] { hidden=(1280, 640, 192), dropout=0.05, batch_size=1024, learning_rate=0.0008, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9788±0.0003 | t=18.1s | tasks=3\n",
      "[A 30/30] { hidden=(1280, 640, 320), dropout=0.05, batch_size=2048, learning_rate=0.0008, label_smoothing=0.0, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9756±0.0002 | t=17.8s | tasks=3\n",
      "\n",
      "=== Phase B: N=8, tasks=6, phase=B ===\n",
      "[B 1/8] { hidden=(1280, 640, 256), dropout=0.05, batch_size=1024, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9844±0.0010 | t=18.5s | tasks=6\n",
      "[B 2/8] { hidden=(1280, 384, 192), dropout=0.1, batch_size=1024, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9847±0.0002 | t=15.0s | tasks=6\n",
      "[B 3/8] { hidden=(1280, 512, 192), dropout=0.05, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9845±0.0004 | t=16.6s | tasks=6\n",
      "[B 4/8] { hidden=(1280, 512, 320), dropout=0.1, batch_size=1024, learning_rate=0.0008, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9845±0.0006 | t=18.5s | tasks=6\n",
      "[B 5/8] { hidden=(1024, 384, 320), dropout=0.05, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9842±0.0012 | t=13.6s | tasks=6\n",
      "[B 6/8] { hidden=(1024, 512, 320), dropout=0.1, batch_size=1024, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9842±0.0006 | t=15.4s | tasks=6\n",
      "[B 7/8] { hidden=(1024, 640, 320), dropout=0.1, batch_size=2048, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9819±0.0003 | t=17.0s | tasks=6\n",
      "[B 8/8] { hidden=(1024, 640, 192), dropout=0.05, batch_size=2048, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9803±0.0004 | t=16.3s | tasks=2 PRUNE[A]\n",
      "\n",
      "=== Phase C: N=3, tasks=10, phase=None ===\n",
      "[C 1/3] { hidden=(1280, 384, 192), dropout=0.1, batch_size=1024, learning_rate=0.0009, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9848±0.0004 | t=17.1s | tasks=10\n",
      "[C 2/3] { hidden=(1280, 512, 320), dropout=0.1, batch_size=1024, learning_rate=0.0008, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9844±0.0006 | t=21.9s | tasks=10\n",
      "[C 3/3] { hidden=(1280, 512, 192), dropout=0.05, batch_size=1024, learning_rate=0.001, label_smoothing=0.05, max_epochs=10, val_fraction=0.1, weight_decay=0.0001 }  ->  acc=0.9844±0.0006 | t=21.5s | tasks=10\n",
      "\n",
      "[3-LAYER quick] TOP-3 (tri = acc desc, puis temps asc)\n",
      "#1 cfg={'hidden': (1280, 384, 192), 'dropout': 0.1, 'batch_size': 1024, 'learning_rate': 0.0009, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001} | acc=0.9848 | t=17.1s\n",
      "#2 cfg={'hidden': (1280, 512, 320), 'dropout': 0.1, 'batch_size': 1024, 'learning_rate': 0.0008, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001} | acc=0.9844 | t=21.9s\n",
      "#3 cfg={'hidden': (1280, 512, 192), 'dropout': 0.05, 'batch_size': 1024, 'learning_rate': 0.001, 'label_smoothing': 0.05, 'max_epochs': 10, 'val_fraction': 0.1, 'weight_decay': 0.0001} | acc=0.9844 | t=21.5s\n"
     ]
    }
   ],
   "source": [
    "AGENT_SPEC = (\"models.MLP.agent_mlp_v3\", \"Agent\")\n",
    "OUTDIR = Path(\"./experiments/exp_3L\")\n",
    "\n",
    "hidden = hidden_from_lists(\n",
    "    [[896, 1024, 1280],  # H1\n",
    "     [384, 512, 640],    # H2\n",
    "     [192, 256, 320]],   # H3\n",
    "    enforce_nonincreasing=True\n",
    ")\n",
    "space = grid_MLP(\n",
    "    hidden_tuples=hidden,\n",
    "    dropout=[0.05, 0.10],\n",
    "    batch_size=[1024, 2048, 3072],\n",
    "    learning_rate=[8e-4, 9e-4, 1.0e-3],\n",
    "    label_smoothing=[0.0, 0.05]\n",
    ")\n",
    "\n",
    "tasks = preset_tasks(\"quick\")\n",
    "prune = preset_pruning(depth=3, strictness=\"std\")\n",
    "\n",
    "exp = make_experiment(AGENT_SPEC, space, OUTDIR, tasks, prune)\n",
    "res_3L = run_and_report(\"3-LAYER quick\", exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
