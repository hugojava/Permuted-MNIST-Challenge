{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa848c8",
   "metadata": {},
   "source": [
    "# MLP AGENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57afdb7",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebce2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    base_path = os.path.dirname(__file__)\n",
    "except NameError:\n",
    "    base_path = os.getcwd()\n",
    "\n",
    "# 1️⃣ Ajouter le dossier parent (un cran au-dessus)\n",
    "parent_dir = os.path.abspath(os.path.join(base_path, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# 2️⃣ Ajouter le dossier parent du dossier parent (deux crans au-dessus)\n",
    "two_up_dir = os.path.abspath(os.path.join(base_path, '..', '..'))\n",
    "sys.path.append(two_up_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ad67c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Import the environment and agents\n",
    "from permuted_mnist.env.permuted_mnist import PermutedMNISTEnv\n",
    "from models.MLP.mlp_v0 import Agent as MLP_baseline_Agent\n",
    "from models.MLP.agent_Peter_Parker import Agent as Peter_Parker_Agent\n",
    "from models.MLP.agent_Bruce_Wayne import Agent as Bruce_Wayne_Agent\n",
    "from models.MLP.agent_mario import Agent as Mario_Agent\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf128e2c",
   "metadata": {},
   "source": [
    "We fix the seed for reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5056ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b326bc9",
   "metadata": {},
   "source": [
    "We fix the number of CPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb6efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85150b15",
   "metadata": {},
   "source": [
    "## 2. Create the Environment\n",
    "\n",
    "Let's create an environment with 10 different permuted tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7171540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created with 10 permuted tasks\n",
      "Training set size: 60000 samples\n",
      "Test set size: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "# Create environment with 10 episodes (tasks)\n",
    "env = PermutedMNISTEnv(number_episodes=10)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "env.set_seed(seed)\n",
    "\n",
    "print(f\"Environment created with {env.number_episodes} permuted tasks\")\n",
    "print(f\"Training set size: {env.train_size} samples\")\n",
    "print(f\"Test set size: {env.test_size} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e8288",
   "metadata": {},
   "source": [
    "## MLP :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ceb9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(Agent):\n",
    "    # Reset environment for fresh start\n",
    "    env.reset()\n",
    "    env.set_seed(seed)\n",
    "\n",
    "    # Create MLP agent\n",
    "    mlp_agent = Agent()\n",
    "\n",
    "    # Track performance\n",
    "    mlp_accuracies = []\n",
    "    mlp_times = []\n",
    "\n",
    "    print(f\"Evaluating Agent:\")\n",
    "\n",
    "    # Evaluate on all tasks\n",
    "    task_num = 1\n",
    "    while True:\n",
    "        task = env.get_next_task()\n",
    "        if task is None:\n",
    "            break\n",
    "        if task_num >= 4: # limited for quick test\n",
    "            break\n",
    "            \n",
    "        # Reset agent for new task\n",
    "        mlp_agent.reset()\n",
    "    \n",
    "        start_time = time.time()\n",
    "    \n",
    "        # Train\n",
    "        mlp_agent.train(task['X_train'], task['y_train'])\n",
    "    \n",
    "        # Make predictions\n",
    "        predictions = mlp_agent.predict(task['X_test'])\n",
    "    \n",
    "        # Calculate time and accuracy\n",
    "        elapsed_time = time.time() - start_time\n",
    "        accuracy = env.evaluate(predictions, task['y_test'])\n",
    "    \n",
    "        mlp_accuracies.append(accuracy)\n",
    "        mlp_times.append(elapsed_time)\n",
    "    \n",
    "        print(f\"Task {task_num}: Accuracy = {accuracy:.2%}, Time = {elapsed_time:.4f}s\")\n",
    "        task_num += 1\n",
    "\n",
    "    mean_accuracy = np.mean(mlp_accuracies)\n",
    "    std_accuracy = np.std(mlp_accuracies)\n",
    "    total_time = np.sum(mlp_times)\n",
    "\n",
    "    print(f\"\\nMLP Agent Summary:\")\n",
    "    print(f\"  Mean accuracy: {mean_accuracy:.2%} ± {std_accuracy:.2%}\")\n",
    "    print(f\"  Total time: {total_time:.2f}s\")\n",
    "\n",
    "    return mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce10cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Agent:\n",
      "epoch 0: 0.9664%\n",
      "epoch 1: 0.9687%\n",
      "epoch 2: 0.9756%\n",
      "epoch 3: 0.9768%\n",
      "epoch 4: 0.9775%\n",
      "epoch 5: 0.9779%\n",
      "epoch 6: 0.9769%\n",
      "epoch 7: 0.9785%\n",
      "epoch 8: 0.9794%\n",
      "epoch 9: 0.9805%\n",
      "Task 1: Accuracy = 98.16%, Time = 150.4125s\n",
      "epoch 0: 0.9653%\n",
      "epoch 1: 0.9702%\n",
      "epoch 2: 0.9782%\n",
      "epoch 3: 0.9786%\n",
      "epoch 4: 0.9741%\n",
      "epoch 5: 0.9786%\n",
      "epoch 6: 0.9796%\n",
      "epoch 7: 0.9818%\n",
      "epoch 8: 0.9805%\n",
      "epoch 9: 0.9790%\n",
      "Task 2: Accuracy = 98.03%, Time = 170.2253s\n",
      "epoch 0: 0.9606%\n",
      "epoch 1: 0.9703%\n",
      "epoch 2: 0.9765%\n",
      "epoch 3: 0.9753%\n",
      "epoch 4: 0.9798%\n",
      "epoch 5: 0.9792%\n",
      "epoch 6: 0.9802%\n",
      "epoch 7: 0.9818%\n",
      "epoch 8: 0.9807%\n",
      "epoch 9: 0.9824%\n",
      "Task 3: Accuracy = 98.23%, Time = 196.5495s\n",
      "\n",
      "MLP Agent Summary:\n",
      "  Mean accuracy: 98.14% ± 0.08%\n",
      "  Total time: 517.19s\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = MLP(MLP_baseline_Agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf35626",
   "metadata": {},
   "source": [
    "Le MLP baseline offre de bonnes performances en prédiction, mais son entraînement est trop long. Nous allons explorer des architectures plus efficaces qui réduisent le temps d’entraînement et de prédiction tout en maintenant un niveau de précision comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d56b237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Agent:\n",
      "Task 1: Accuracy = 96.10%, Time = 60.7351s\n",
      "Task 2: Accuracy = 95.86%, Time = 59.7669s\n",
      "Task 3: Accuracy = 97.44%, Time = 60.3781s\n",
      "\n",
      "MLP Agent Summary:\n",
      "  Mean accuracy: 96.47% ± 0.70%\n",
      "  Total time: 180.88s\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = MLP(Peter_Parker_Agent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb955156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Agent:\n",
      "Task 1: Accuracy = 98.12%, Time = 59.6177s\n",
      "Task 2: Accuracy = 98.10%, Time = 60.0172s\n",
      "Task 3: Accuracy = 97.83%, Time = 59.6846s\n",
      "\n",
      "MLP Agent Summary:\n",
      "  Mean accuracy: 98.02% ± 0.13%\n",
      "  Total time: 179.32s\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = MLP(Bruce_Wayne_Agent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80caa37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Agent:\n",
      "Task 1: Accuracy = 98.21%, Time = 60.1239s\n",
      "Task 2: Accuracy = 98.07%, Time = 59.8997s\n",
      "Task 3: Accuracy = 97.83%, Time = 59.5425s\n",
      "\n",
      "MLP Agent Summary:\n",
      "  Mean accuracy: 98.04% ± 0.16%\n",
      "  Total time: 179.57s\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = MLP(Mario_Agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3679e03",
   "metadata": {},
   "source": [
    "Nous avons identifié des architectures de MLP plus performantes que nos modèles précédents. Ces nouvelles configurations offrent de meilleurs résultats tout en respectant les contraintes de temps, de CPU et de mémoire imposées par le problème."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
